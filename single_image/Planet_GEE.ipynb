{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marroca13/PSeagrasS2/blob/main/single_image/Planet_GEE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n5oh5WCsRYn"
      },
      "source": [
        "# **Blending PlanetScope and Sentinel-2 imagery for seagrass change detection**\n",
        "*Diclaimer: your imagery has to be atmospherically corrected, thats why we integrate ACOLITE processor into the workflow (default settings, v20231023.0). If prefered, you can also use your corrected imagery avoiding step 1 and importing them to Drive or GEE as an asset.*\n",
        "\n",
        "*This code has been developed for the eutrophic Lagoa da ConceiÃ§ao in Florianopolis (Brazil).*\n",
        "\n",
        "---\n",
        "\n",
        "The code includes:\n",
        "1. PlanetScope import\n",
        "2. ODW and land adjacent pixels masking\n",
        "3. -\n",
        "4. Preparation of in situ data: training and validation sets\n",
        "5. Depth invariant index and band ratios calculation over Sentinel-2\n",
        "6. Random Forest: binary classification\n",
        "  6.1. Pre-event + uncertainty assessment\n",
        "  6.2. Post-event + uncertainty assessment\n",
        "7. Seagrass change quantification\n",
        "\n",
        "\n",
        "> **Mar Roca Mora**\n",
        "Last update: 2025/06/11\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYnUwfkbglaD"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "817qxsc-gpA8"
      },
      "outputs": [],
      "source": [
        "!pip install xlsxwriter\n",
        "!pip install geemap\n",
        "!pip install rioxarray\n",
        "!pip install earthengine-api\n",
        "!pip install scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHJSLzJ2unAe"
      },
      "source": [
        "# 0 - Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPzi0bSmj5TQ"
      },
      "outputs": [],
      "source": [
        "## Connection to GEE project\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='your-project') #set your GEE project here\n",
        "\n",
        "## Connection to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0FbtfXvVczFD"
      },
      "outputs": [],
      "source": [
        "## Import some libraries\n",
        "import os\n",
        "import ee\n",
        "import geemap\n",
        "import geemap.colormaps as cm\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import rioxarray\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16aOvtCMj0Bk"
      },
      "outputs": [],
      "source": [
        "geemap.ee_initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L1IeoQNdKre"
      },
      "outputs": [],
      "source": [
        "## Clone GitHub repo:\n",
        "##!git clone https://github.com/marroca13/seagrass_PS_S2.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUAmKPh3qa_r"
      },
      "source": [
        "\n",
        "\n",
        "# 1 - Atmospheric correction - ACOLITE inside GEE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6RNYZsSAvXa"
      },
      "source": [
        "## PlanetScope imagery\n",
        "*If the area has more than one tile, merge first through ACOLITE using merge_tiles = TRUE*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NiCk0jUBN0t"
      },
      "outputs": [],
      "source": [
        "## Import PlanetScope Imagery already processed and uploaded as an asset\n",
        "\n",
        "## If you have a Planet account linked to GEE, you can process everything on the cloud\n",
        "planetScope18 = ee.Image('projects/ee-seagrass-mar/assets/Brazil/PlanetScope_2018') # 4-bands 2259x4305 px\n",
        "bands18 = ['B1', 'B2', 'B3', 'B4', 'Kd_505', 'KPAR']\n",
        "planetScope18 = planetScope18.select(planetScope18.bandNames()).rename(['B1', 'B2', 'B3', 'B4', 'flags', 'Kd_505', 'KPAR']).select(bands18)\n",
        "print(planetScope18.bandNames().getInfo())\n",
        "\n",
        "\n",
        "planetScope24 = ee.Image('projects/ee-seagrass-mar/assets/Brazil/PlanetScope_2024') # 8-bands 2259x4305 px\n",
        "bands24 = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'Kd_492', 'KPAR'] # ['B2', 'B4', 'B6', 'B8', 'Kd_492', 'KPAR']\n",
        "planetScope24 = planetScope24.select(planetScope24.bandNames()).rename(['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'flags', 'Kd_492', 'KPAR']).select(bands24)\n",
        "print(planetScope24.bandNames().getInfo())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-C_AY6fWkAlf"
      },
      "outputs": [],
      "source": [
        "rgb_plot_ps = {\n",
        "    'bands': ['B3', 'B2', 'B1'],\n",
        "    'gamma': 1.4,\n",
        "    'min': -0.003069632846763851,\n",
        "    'max': 0.023891219740272425}\n",
        "\n",
        "rgb_plot_ps_24 = {\n",
        "    'bands': ['B6', 'B4', 'B2'],\n",
        "    'min': 0.0017,\n",
        "    'max': 0.031,\n",
        "    'gamma': 1.4\n",
        "}\n",
        "\n",
        "Map = geemap.Map()\n",
        "Map.addLayer(planetScope18, rgb_plot_ps, \"PlanetScope 2018\")\n",
        "Map.addLayer(planetScope24, rgb_plot_ps_24, \"PlanetScope 2024\")\n",
        "Map.centerObject(planetScope18, 11)\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzS6h86aF0yr"
      },
      "source": [
        "\n",
        "# 2 - Optically deep water (ODW) and land pixel masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aonSuSYcrF7K"
      },
      "outputs": [],
      "source": [
        "# For the ODW masking we used a delimitation from 1-meter secchi disk for 2024 processed for Sentinel-2 imagery.\n",
        "OSW = ee.FeatureCollection('projects/ee-seagrass-mar/assets/Brazil/OSW_zSD_new')\n",
        "bathy = ee.Image('projects/ee-seagrass-mar/assets/Brazil/Batimetria_Lagoa')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVKbiwkoJ2rj"
      },
      "outputs": [],
      "source": [
        "ndwi24 = planetScope24.normalizedDifference(['B8', 'B4'])\n",
        "land_mask = ndwi24.lt(0.1)\n",
        "\n",
        "Map.addLayer(land_mask, {'palette': 'orange'}, \"Land Mask 24\")\n",
        "# Map.addLayer(OSW, {'color': 'yellow'}, \"OSW\")\n",
        "# Map.centerObject(land_mask, 11)\n",
        "# Map\n",
        "\n",
        "zSD = ee.Image('projects/ee-seagrass-mar/assets/Brazil/PlanetScope_24').select('zSD')\n",
        "zSD = zSD.updateMask(zSD.lte(1))\n",
        "land_mask = ndwi24.lt(0.1).And(zSD.lte(1))\n",
        "Map.addLayer(land_mask, {'palette': 'orange'}, \"Shallow water mask\")\n",
        "# Map.centerObject(land_mask, 11)\n",
        "# Map\n",
        "\n",
        "Map.addLayer(zSD, {\"min\":0,\"max\":1,\"palette\":[\"e0f7fa\",\"b2ebf2\",\"81d4fa\",\"4fc3f7\",\"29b6f6\",\"039be5\",\"0288d1\",\"0277bd\",\"01579b\",\"003f5c\"]}, \"zSD\")\n",
        "Map.centerObject(zSD, 11)\n",
        "Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArNxpV7aszp1"
      },
      "outputs": [],
      "source": [
        "\n",
        "planetScope18 = planetScope18.clip(OSW).updateMask(land_mask).select(['B1', 'B2', 'B3', 'B4', 'Kd_505', 'KPAR']) ## try remove B4 (NIR)\n",
        "planetScope24 = planetScope24.clip(OSW).updateMask(land_mask).select(['B1','B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'Kd_492', 'KPAR']) ## try remove B8 (NIR)\n",
        "\n",
        "Map.centerObject(land_mask, 11)\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgqHAHL0EZy"
      },
      "source": [
        "# 4 - Preparation of *in situ* data: training and validation sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooqPfZzr_8xR"
      },
      "source": [
        "Field sample data have the following classes as 'Bottom':\n",
        "\n",
        " 0 - seagrass (Halodule or Ruppia)\n",
        "\n",
        " 1 - nonSeagrass (sand, mud, rock, algae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRh2MbGO0LwF"
      },
      "outputs": [],
      "source": [
        "\n",
        "insitu2018 = ee.FeatureCollection('projects/ee-seagrass-mar/assets/Brazil/fieldData18').filterBounds(OSW)\n",
        "sand18 = insitu2018.filter(ee.Filter.eq('Bottom', 'sand'))\n",
        "# print('Total samples 2018:', insitu2018.size().getInfo())\n",
        "# print('Sand sample 2018:',sand18.size().getInfo())\n",
        "\n",
        "# in situ 2024 has 6 different bottom types: sand, mud, rock, algae, Halodule and Ruppia species, so we'll group them later ['Halodule, 'Ruppia'] == seagrass\n",
        "insitu2024 = ee.FeatureCollection('projects/ee-seagrass-mar/assets/Brazil/fieldData24').filterBounds(OSW)\n",
        "\n",
        "# Filter for sand class and get size on the server side\n",
        "sand24 = insitu2024.filter(ee.Filter.eq('Bottom', 'sand'))\n",
        "# seagrass24 = insitu2024.filter(ee.Filter.inList('Bottom', ['Halodule', 'Ruppia'])) # Keep this commented out as it was before\n",
        "# print('Total samples 2024:', insitu2024.size().getInfo())\n",
        "# print('Sand sample 2024:', sand24.size().getInfo())\n",
        "# print('Seagrass sample 2024:',seagrass24.size().getInfo()) # Keep this commented out as it was before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOBNMNW0LtEC"
      },
      "outputs": [],
      "source": [
        "Map.addLayer(insitu2018, {'color': 'darkgreen'}, 'in situ 2018')\n",
        "Map.addLayer(insitu2024, {'color': 'lightgreen'}, 'in situ 2024')\n",
        "# Map.addLayer(land_mask, {'color': 'blue'}, 'secchi_mask')\n",
        "Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYHBHIRBF8SX"
      },
      "outputs": [],
      "source": [
        "# Map the sampling function to the ImageCollection\n",
        "sampledData_2018 = planetScope18.sampleRegions(collection=insitu2018,\n",
        "        properties=['Bottom'],\n",
        "        scale=3,\n",
        "        geometries=True)\n",
        "\n",
        "# print('sampledData 2018:', sampledData_2018.size().getInfo())\n",
        "\n",
        "# Map the sampling function to the ImageCollection\n",
        "sampledData_2024 = planetScope24.sampleRegions(\n",
        "        collection=insitu2024,\n",
        "        properties=['Bottom'],\n",
        "        scale=3,\n",
        "        geometries=True)\n",
        "\n",
        "sampledData_2024\n",
        "sampledData_2018"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s11Zn0bpf_Ht"
      },
      "outputs": [],
      "source": [
        "## Split training and validation sets ## Be sure in a Random Forest that the dataset is balanced (50%/50% of each class)\n",
        "## 2018\n",
        "filtered_18_seagrass = insitu2018.filter(ee.Filter.eq('Bottom', 'seagrass')).randomColumn('random')\n",
        "filtered_18_nonSeagrass = insitu2018.filter(ee.Filter.eq('Bottom', 'sand')).randomColumn('random')\n",
        "\n",
        "# Get the count of seagrass and sand points in filtered_18\n",
        "seagrass_samples_18 = filtered_18_seagrass.limit(90)\n",
        "nonSeagrass_samples_18 = filtered_18_nonSeagrass.limit(90)\n",
        "\n",
        "seagrass_count_18 = seagrass_samples_18.size().getInfo()\n",
        "nonSeagrass_count_18 = nonSeagrass_samples_18.size().getInfo()\n",
        "\n",
        "# Create labels and counts for the bar chart\n",
        "labels = ['Seagrass', 'Non-Seagrass']\n",
        "counts = [seagrass_count_18, nonSeagrass_count_18]\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(labels, counts, color=['green', 'darkorange'])\n",
        "plt.ylabel('Number of Points')\n",
        "plt.title('Distribution of Seagrass vs. Sand Points in filtered_18')\n",
        "plt.show()\n",
        "\n",
        "## 2024\n",
        "filtered_24_seagrass = insitu2024.filter(ee.Filter.inList('Bottom', ['Hadolule', 'Ruppia'])).randomColumn('random')\n",
        "filtered_24_nonSeagrass = insitu2024.filter(ee.Filter.inList('Bottom', ['sand',  'mud'])).randomColumn('random')\n",
        "\n",
        "## 2024\n",
        "# Separate features by class groupings\n",
        "seagrass_samples_24 = filtered_24_seagrass.filter(ee.Filter.inList('Bottom', ['Hadolule', 'Ruppia'])).limit(60)\n",
        "nonSeagrass_samples_24 = filtered_24_nonSeagrass.filter(ee.Filter.inList('Bottom', ['sand',  'mud', 'rock', 'algae'])).limit(60) # Adjust this list based on your non-seagrass classes\n",
        "\n",
        "# Get the count of seagrass and non-seagrass points in filtered_24\n",
        "seagrass_count_24 = seagrass_samples_24.size().getInfo()\n",
        "nonSeagrass_count_24 = nonSeagrass_samples_24.size().getInfo()\n",
        "\n",
        "# Create labels and counts for the bar chart\n",
        "labels = ['Seagrass', 'Non-Seagrass']\n",
        "counts = [seagrass_count_24, nonSeagrass_count_24]\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(labels, counts, color=['green', 'darkorange'])\n",
        "plt.ylabel('Number of Points')\n",
        "plt.title('Distribution of Seagrass vs. Non-Seaglass Points in filtered_24')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2n4tXCzj7c5u"
      },
      "outputs": [],
      "source": [
        "## Split training and validation sets\n",
        "## 2018\n",
        "t_seagrass_pre = seagrass_samples_18.filter(ee.Filter.eq('Bottom', 'seagrass')).filter(ee.Filter.lt('random', 0.7))\n",
        "v_seagrass_pre = seagrass_samples_18.filter(ee.Filter.eq('Bottom', 'seagrass')).filter(ee.Filter.gte('random', 0.7))\n",
        "t_nonSeagrass_pre = nonSeagrass_samples_18.filter(ee.Filter.eq('Bottom', 'sand')).filter(ee.Filter.lt('random', 0.7))\n",
        "v_nonSeagrass_pre = nonSeagrass_samples_18.filter(ee.Filter.eq('Bottom', 'sand')).filter(ee.Filter.gte('random', 0.7))\n",
        "validation_pre = v_seagrass_pre.merge(v_nonSeagrass_pre)\n",
        "print('Training pre:', t_seagrass_pre.merge(t_nonSeagrass_pre).size().getInfo())\n",
        "print('t_seagrass_pre:', t_seagrass_pre.size().getInfo())\n",
        "print('t_nonSeagrass_pre:', t_nonSeagrass_pre.size().getInfo())\n",
        "print('Validation pre:', validation_pre.size().getInfo())\n",
        "print('v_seagrass_pre:', v_seagrass_pre.size().getInfo())\n",
        "print('v_nonSeagrass_pre:', v_nonSeagrass_pre.size().getInfo())\n",
        "\n",
        "## 2024\n",
        "t_seagrass_post = seagrass_samples_24.filter(ee.Filter.inList('Bottom', ['Hadolule', 'Ruppia'])).filter(ee.Filter.lt('random', 0.7))\n",
        "v_seagrass_post = seagrass_samples_24.filter(ee.Filter.inList('Bottom', ['Hadolule', 'Ruppia'])).filter(ee.Filter.gte('random', 0.7))\n",
        "t_nonSeagrass_post = nonSeagrass_samples_24.filter(ee.Filter.inList('Bottom', ['sand',  'mud'])).filter(ee.Filter.lt('random', 0.7)) ##['sand', 'rock', 'mud', 'algae']))\n",
        "v_nonSeagrass_post = nonSeagrass_samples_24.filter(ee.Filter.inList('Bottom', ['sand', 'mud'])).filter(ee.Filter.gte('random', 0.7)) ## Try including only sand and mud\n",
        "validation_post = v_seagrass_post.merge(v_nonSeagrass_post)\n",
        "print('Training post:', t_seagrass_post.merge(t_nonSeagrass_post).size().getInfo())\n",
        "print('t_seagrass_post:', t_seagrass_post.size().getInfo())\n",
        "print('t_nonSeagrass_post:', t_nonSeagrass_post.size().getInfo())\n",
        "print('Validation post:', v_seagrass_post.merge(v_nonSeagrass_post).size().getInfo())\n",
        "print('v_seagrass_post:', v_seagrass_post.size().getInfo())\n",
        "print('v_nonSeagrass_post:', v_nonSeagrass_post.size().getInfo())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkUkRoVY6Nae"
      },
      "source": [
        "# 5 - Depth Invariant Index (DII) - B2B3 for both sensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8WCin85Vk1T"
      },
      "outputs": [],
      "source": [
        "# Rename bands for PlanetScope\n",
        "ps_prefix = 'PS_'\n",
        "planetScope18 = planetScope18.rename(planetScope18.bandNames().map(lambda band: ee.String(ps_prefix).cat(band)))\n",
        "# Rename bands for PlanetScope\n",
        "ps_prefix = 'PS_'\n",
        "planetScope24 = planetScope24.rename(planetScope24.bandNames().map(lambda band: ee.String(ps_prefix).cat(band)))\n",
        "planetScope18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGDBSxD5jODb"
      },
      "outputs": [],
      "source": [
        "# For PlanetScope Classic\n",
        "def PSC_depthInvariant(image):\n",
        "  band1 = ['PS_B1', 'PS_B2', 'PS_B1']\n",
        "  band2 = ['PS_B2', 'PS_B3', 'PS_B3']\n",
        "  nband = ['PS_B1B2', 'PS_B2B3', 'PS_DII']\n",
        "\n",
        "  for i in range(3):\n",
        "    x = band1[i]\n",
        "    y = band2[i]\n",
        "    z = nband[i]\n",
        "\n",
        "    imageLog = image.select([x, y]).log()\n",
        "\n",
        "    sand = insitu2018.filter(ee.Filter.eq('Bottom', 'sand'))\n",
        "\n",
        "    covariance = imageLog.toArray().reduceRegion(\n",
        "        reducer=ee.Reducer.covariance(),\n",
        "        geometry=sand,\n",
        "        scale=3,\n",
        "        maxPixels=1e13,\n",
        "        bestEffort=True\n",
        "    )\n",
        "\n",
        "    covarMatrix = ee.Array(covariance.get('array'))\n",
        "    var1 = covarMatrix.get([0, 0])\n",
        "    var2 = covarMatrix.get([1, 1])\n",
        "    covar = covarMatrix.get([0, 1])\n",
        "\n",
        "    a = (var1.subtract(var2)).divide(covar.multiply(2))\n",
        "    attenCoeffRatio = a.add(((a.pow(2)).add(1)).sqrt())\n",
        "\n",
        "    depthInvariantIndex = image.expression(\n",
        "        'image1 - (image2 * coeff)', {\n",
        "            'image1': imageLog.select([x]),\n",
        "            'image2': imageLog.select([y]),\n",
        "            'coeff': attenCoeffRatio\n",
        "        }\n",
        "    )\n",
        "\n",
        "    image = image.addBands(depthInvariantIndex.select([x], [z])) # Corrected index to 0 as expression returns a single band\n",
        "\n",
        "  return image\n",
        "\n",
        "# For PlanetScope SuperDove\n",
        "def PSSD_depthInvariant(image):\n",
        "  band1 = ['PS_B2', 'PS_B3', 'PS_B2']\n",
        "  band2 = ['PS_B3', 'PS_B4', 'PS_B4']\n",
        "  nband = ['PS_B2B3', 'PS_B3B4', 'PS_DII']\n",
        "\n",
        "  for i in range(3):\n",
        "    x = band1[i]\n",
        "    y = band2[i]\n",
        "    z = nband[i]\n",
        "\n",
        "    imageLog = image.select([x, y]).log()\n",
        "\n",
        "    sand = insitu2024.filter(ee.Filter.eq('Bottom', 'sand'))\n",
        "\n",
        "    covariance = imageLog.toArray().reduceRegion(\n",
        "        reducer=ee.Reducer.covariance(),\n",
        "        geometry=sand,\n",
        "        scale=3,\n",
        "        maxPixels=1e13,\n",
        "        bestEffort=True\n",
        "    )\n",
        "\n",
        "    covarMatrix = ee.Array(covariance.get('array'))\n",
        "    var1 = covarMatrix.get([0, 0])\n",
        "    var2 = covarMatrix.get([1, 1])\n",
        "    covar = covarMatrix.get([0, 1])\n",
        "\n",
        "    a = (var1.subtract(var2)).divide(covar.multiply(2))\n",
        "    attenCoeffRatio = a.add(((a.pow(2)).add(1)).sqrt())\n",
        "\n",
        "    depthInvariantIndex = image.expression(\n",
        "        'image1 - (image2 * coeff)', {\n",
        "            'image1': imageLog.select([x]),\n",
        "            'image2': imageLog.select([y]),\n",
        "            'coeff': attenCoeffRatio\n",
        "        }\n",
        "    )\n",
        "\n",
        "    image = image.addBands(depthInvariantIndex.select([x], [z])) # Corrected index to 0 as expression returns a single band\n",
        "\n",
        "  return image\n",
        "\n",
        "# Apply to your image collection (e.g., multi_sensor_pre or multi_sensor_post)\n",
        "multi_sensor_pre = PSC_depthInvariant(planetScope18)\n",
        "multi_sensor_post = PSSD_depthInvariant(planetScope24)\n",
        "multi_sensor_post"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnHVgme88Ml8"
      },
      "source": [
        "# 6 - Binary classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDjKdPXu1N9f"
      },
      "source": [
        "## 6.1 - Pre-event Multi-sensor Image Collection\n",
        "#### Before processing all data, the best seagrass probability threshold was studied and set as t = 45"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAVChVMEfPJQ"
      },
      "outputs": [],
      "source": [
        "# Binary classification setup\n",
        "seagrass_class = 0\n",
        "nonSeagrass_class = 1\n",
        "\n",
        "# Classification and validation parameters\n",
        "trees = 50\n",
        "t = 45\n",
        "\n",
        "# Boxcar kernel: a square matrix where all values are equal, and it calculates the mean of the pixel values within that square neighborhood.\n",
        "boxcar = ee.Kernel.square(radius=2, units='pixels', normalize=True)\n",
        "bands = multi_sensor_pre.bandNames()\n",
        "\n",
        "def boxcar_image(image):\n",
        "    return image.convolve(boxcar)\n",
        "\n",
        "# Apply the function to every image in the collection\n",
        "classificationComp_pre = boxcar_image(multi_sensor_pre)\n",
        "classificationComp_pre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mj4uP2Dy0l7"
      },
      "source": [
        " ##### 6.1.1 - Prepare training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8MPF_cC22dL"
      },
      "outputs": [],
      "source": [
        "# Training data - class property recoding and merging - MODEL 1 (PRE-EVENT)\n",
        "t_seagrass = t_seagrass_pre.map(lambda x: x.setMulti(ee.Dictionary.fromLists(['habitat'], [seagrass_class])))\n",
        "t_nonSeagrass = t_nonSeagrass_pre.map(lambda x: x.setMulti(ee.Dictionary.fromLists(['habitat'], [nonSeagrass_class])))\n",
        "t_FC = t_seagrass.merge(t_nonSeagrass)\n",
        "\n",
        "\n",
        "# Collect sampled features from each image\n",
        "def sample_image(image):\n",
        "    sampled = image.sampleRegions(\n",
        "        collection=t_FC,\n",
        "        scale=3,\n",
        "        geometries=True\n",
        "    ).filter(ee.Filter.notNull(bands))\n",
        "\n",
        "    return sampled\n",
        "\n",
        "# Map the sampling function and convert result to a list of FeatureCollections\n",
        "sampledData = sample_image(classificationComp_pre)\n",
        "\n",
        "# Using sampleRegions we take values across the Image Collection. getting valid FeatureCollection when overlapping with pixels\n",
        "print('sampledData:', sampledData.size().getInfo())\n",
        "print('t_FC:', t_FC.size().getInfo())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIHaemWuAMMK"
      },
      "source": [
        "6.1.2 - Extract probabilities for each class and train classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4jUchzkVbRO"
      },
      "outputs": [],
      "source": [
        "## To extract feature importance and evaluate\n",
        "def soft_prob_subfn(image, num):\n",
        "       training = sampledData.map(lambda ft: ft.set(\n",
        "        'prob',\n",
        "        ee.Algorithms.If(ft.getNumber('habitat').eq(num), 1, 0)\n",
        "        ))\n",
        "\n",
        "       trained = ee.Classifier.smileRandomForest(numberOfTrees=trees) \\\n",
        "           .train(training, 'prob', image.bandNames()) \\\n",
        "           .setOutputMode('PROBABILITY')\n",
        "\n",
        "       dict_classifier = trained.explain()\n",
        "\n",
        "       # Create a Feature with the dictionary as a property\n",
        "       feature = ee.Feature(None, {'classifier_explanation': dict_classifier})\n",
        "\n",
        "       # Classify and convert to percentage scale\n",
        "       classified = image.classify(trained).multiply(100).toInt8()\n",
        "\n",
        "       # Return both the classified image and the Feature with explanation\n",
        "       return ee.Image(classified).set('classifier_explanation', feature)\n",
        "\n",
        "# Apply the function to the single image\n",
        "seagrass_prob_image = soft_prob_subfn(classificationComp_pre, seagrass_class)\n",
        "nonSeagrass_prob_image = soft_prob_subfn(classificationComp_pre, nonSeagrass_class)\n",
        "\n",
        "# You can now work with seagrass_prob_image and nonSeagrass_prob_image\n",
        "\n",
        "### FEATURE IMPORTANCE\n",
        "seagrass_prob_image\n",
        "\n",
        "# # Initialize an empty dictionary to store feature importances\n",
        "# mean_importance = {}\n",
        "\n",
        "# # Iterate through the first three images\n",
        "# for i in range(1):\n",
        "#   image = ee.Image(seagrass_prob_image.get(i))\n",
        "#   classifier_explanation = image.get('classifier_explanation').getInfo()['properties']['classifier_explanation']\n",
        "#   importance_dict = classifier_explanation.get('importance')\n",
        "\n",
        "#   # Accumulate feature importances\n",
        "#   for feature, importance in importance_dict.items():\n",
        "#     mean_importance[feature] = mean_importance.get(feature, 1) + importance\n",
        "\n",
        "# # Calculate the mean feature importance\n",
        "# for feature in mean_importance:\n",
        "#   mean_importance[feature]\n",
        "\n",
        "# # Print the mean feature importance\n",
        "# print(mean_importance)\n",
        "\n",
        "# # Sort features by importance in descending order\n",
        "# sorted_importance = dict(sorted(mean_importance.items(), key=lambda item: item[1], reverse=False))\n",
        "\n",
        "# # Extract feature names and importance values\n",
        "# feature_names = list(sorted_importance.keys())\n",
        "# importance_values = list(sorted_importance.values())\n",
        "\n",
        "# # Create a list of colors based on feature name prefix\n",
        "# colors = ['#005b96' if name.startswith('PS_') else '#6497b1' for name in feature_names]\n",
        "\n",
        "# # Create the horizontal bar graph (switched axes)\n",
        "# plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n",
        "# plt.barh(feature_names, importance_values, color=colors) # Changed to barh for horizontal bars\n",
        "# plt.ylabel(\"Features\") # Switched x and y labels\n",
        "# plt.xlabel(\"Importance\") # Switched x and y labels\n",
        "# plt.title(\"Feature Importance Histogram (2018)\")\n",
        "# # plt.axvline(x=10.5, linestyle='dotted', color='grey')  # Add dotted vertical line\n",
        "# plt.show()  # Display the plot\n",
        "# plt.tight_layout()\n",
        "\n",
        "# selected_bands = [band for band, importance in mean_importance.items() if importance >= 0] ## Use only selected bands for the classification ## 10.5 before\n",
        "\n",
        "# print(\"Selected bands:\", selected_bands)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCpwD9Ye5oQT"
      },
      "source": [
        "Analyse covariance between variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQP47h8xySgf"
      },
      "outputs": [],
      "source": [
        "## Co-variance analysis\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "selected_bands = classificationComp_pre.bandNames()\n",
        "\n",
        "# Function to extract band values from a FeatureCollection\n",
        "def extract_band_values(feature_collection, bands):\n",
        "    data = feature_collection.toList(feature_collection.size()).map(lambda feature: ee.Feature(feature).toDictionary().select(bands)).getInfo()\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "# Extract band values for selected bands\n",
        "band_values_df = extract_band_values(sampledData, selected_bands)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = band_values_df.corr()\n",
        "\n",
        "# Create a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(correlation_matrix, bool), k=1)\n",
        "\n",
        "# Apply the mask to the filtered correlation matrix\n",
        "filtered_correlation_matrix = correlation_matrix.mask(mask)\n",
        "filtered_correlation_matrix = filtered_correlation_matrix[np.abs(correlation_matrix) > 0.80]\n",
        "\n",
        "# Get bands with at least one correlation above 0.9\n",
        "bands_to_keep = filtered_correlation_matrix.columns[filtered_correlation_matrix.any()]\n",
        "\n",
        "# Filter the original correlation matrix to keep only relevant bands\n",
        "filtered_correlation_matrix = correlation_matrix.loc[bands_to_keep, bands_to_keep]\n",
        "\n",
        "# Plot only the lower triangle of the correlation matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(filtered_correlation_matrix, mask=mask, annot=True, cmap='coolwarm',\n",
        "            fmt=\".2f\", linewidths=.5, linecolor='lightgrey', square=True,\n",
        "            cbar_kws={\"shrink\": .75})\n",
        "plt.title('Band Covariability Analysis')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Bands to keep:\", bands_to_keep.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyGjsp4AAXc2"
      },
      "source": [
        "6.1.3 - Generate probability layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TH4oE005EqW"
      },
      "outputs": [],
      "source": [
        "## Train classifier and display probability map for seagrasses\n",
        "# Define classes dictionary\n",
        "classes = {\n",
        "  'classes_values': [seagrass_class, nonSeagrass_class],\n",
        "  'classes_names': ['seagrass','nonSeagrass'] # Corrected 'nonSeagrass' spelling\n",
        "}\n",
        "\n",
        "classes\n",
        "\n",
        "# Assume this is already defined:\n",
        "# - classificationComp_pre: an ImageCollection\n",
        "# - classes: dictionary with class values and names\n",
        "# - soft_prob_subfn(image, class_id): returns a probability image for one class\n",
        "\n",
        "def classify_single_image_with_all_classes(image):\n",
        "    \"\"\"\n",
        "    Classifies a single Earth Engine Image for all defined classes.\n",
        "\n",
        "    Args:\n",
        "        image (ee.Image): The Earth Engine Image to classify.\n",
        "\n",
        "    Returns:\n",
        "        ee.Image: A multi-band image with probability bands for each class.\n",
        "    \"\"\"\n",
        "    # Classify image for each class and rename the result accordingly\n",
        "    classified_images = ee.List(classes['classes_values']).map(\n",
        "        lambda class_id: soft_prob_subfn(image, class_id)\n",
        "    )\n",
        "\n",
        "    # Convert list of images into one multi-band image (each class as band)\n",
        "    classified_combined = ee.ImageCollection(classified_images).toBands()\n",
        "    classified_combined = classified_combined.rename(classes['classes_names'])\n",
        "\n",
        "    # Preserve metadata if needed\n",
        "    return classified_combined.copyProperties(image, image.propertyNames())\n",
        "\n",
        "probabilities = classify_single_image_with_all_classes(classificationComp_pre)\n",
        "probabilities\n",
        "# You can now use probabilities_single_image for visualization or further analysis\n",
        "# print(probabilities_single_image.bandNames().getInfo())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSPL9732m1C_"
      },
      "source": [
        "Plot probabilities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "itJ4emCxBk9o"
      },
      "outputs": [],
      "source": [
        "# Visualize probabilities\n",
        "probabilities = ee.Image(probabilities).clip(OSW).updateMask(land_mask)\n",
        "Map = geemap.Map()\n",
        "Map.addLayer(probabilities.select('seagrass'), {'min': 45, 'max': 100}, 'Seagrass Prob')\n",
        "Map.addLayer(probabilities.select('nonSeagrass'), {'min': 45, 'max': 100}, 'NonSeagrass Prob')\n",
        "Map.centerObject(probabilities, zoom=12)\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNagrZ1oDbpo"
      },
      "source": [
        "6.1.4 - Threshold classes based on probabilities and classify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYY-Mvw2BQLB"
      },
      "outputs": [],
      "source": [
        "# Based on the generated probabilities, apply thresholding for seagrass and nonSeagrass on the whole Image Collection\n",
        "\n",
        "# Threshold function for seagrass\n",
        "def threshold_seagrass(image):\n",
        "    return image.select('seagrass').updateMask(image.select('seagrass').gt(t)) \\\n",
        "        .copyProperties(image, image.propertyNames())\n",
        "\n",
        "# Threshold function for non-seagrass\n",
        "def threshold_non_seagrass(image):\n",
        "    return image.select('nonSeagrass').updateMask(image.select('nonSeagrass').gt(t)) \\\n",
        "        .copyProperties(image, image.propertyNames())\n",
        "\n",
        "# Map the thresholding over the probabilities collection\n",
        "seagrass_soft = threshold_seagrass(probabilities)\n",
        "nonSeagrass_soft = threshold_non_seagrass(probabilities)\n",
        "\n",
        "# Combine the thresholded images into a single image (taking the first image from each collection as an example)\n",
        "# If you intend to process all images in the collection, the downstream code needs to be adapted to work with ImageCollections.\n",
        "soft_map = ee.Image(seagrass_soft).addBands(ee.Image(nonSeagrass_soft))\n",
        "soft_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vUUUWdTAiph"
      },
      "source": [
        "6.1.5 - Perform classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh_mn6kSL2Ww"
      },
      "outputs": [],
      "source": [
        "def soft_to_hard(image):\n",
        "    seagrass = image.select('seagrass')\n",
        "    non_seagrass = image.select('nonSeagrass')\n",
        "    prob_aoi = ee.Image(probabilities).geometry()\n",
        "\n",
        "    classified = (ee.Image.constant(2)\n",
        "        .where(seagrass.gte(t), ee.Number(0).add(1))  # temporary +1 to mask 0s\n",
        "        .where(non_seagrass.gte(t), ee.Number(1).add(1))\n",
        "        .selfMask()\n",
        "        .subtract(1)  # back to 0 and 1\n",
        "        .rename('classification')\n",
        "        .clip(prob_aoi))\n",
        "    return classified\n",
        "\n",
        "# Apply to soft_map\n",
        "soft_map_th = soft_to_hard(soft_map)\n",
        "soft_map_th"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELPzK_LjA_8u"
      },
      "source": [
        "6.1.6 - Combine the three classifications for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fluP7YI_Jzhd"
      },
      "outputs": [],
      "source": [
        "# 1. Extract the 'classification' band from each image\n",
        "classification_images_pre = soft_map_th.select('classification').mask(land_mask).clip(OSW)\n",
        "\n",
        "# Display the combined classification\n",
        "Map.addLayer(classification_images_pre, {'min': 0, 'max': 1, 'palette': ['42762f', '7cb75a', 'e2e9ab', 'ffffff']}, 'Combined Classification')\n",
        "Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klDw5KXJv-WM"
      },
      "outputs": [],
      "source": [
        "# # Export the FeatureCollection to Google Drive\n",
        "# task = ee.batch.Export.image.toDrive(\n",
        "#     image=combined_classification_pre,\n",
        "#     description='combined_classification_pre',  # Description for the task\n",
        "#     folder='Colab_Notebooks/export',\n",
        "#     region = OSW.geometry(),\n",
        "#     scale=3,  # Adjust the scale as needed\n",
        "#     fileFormat='GeoTIFF'  # Choose your desired file format (CSV, GeoJSON, KML, SHP, TFRecord)\n",
        "# )\n",
        "\n",
        "# # Start the export task\n",
        "# task.start()\n",
        "\n",
        "# print('Export task started. You can monitor its progress in the \"Tasks\" tab.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHPmTzSsHiVb"
      },
      "outputs": [],
      "source": [
        "# Apply conditional classification for obtain the final binary map\n",
        "classification_images_pre = classification_images_pre.expression(\n",
        "    'b(0) < 0.35 ? 0 : 1',  # Conditional expression\n",
        "    {'classification': classification_images_pre}  # Band name mapping\n",
        ").rename('classification')  # Rename the band\n",
        "\n",
        "# Display the combined classification\n",
        "Map.addLayer(classification_images_pre.mask(land_mask).clip(OSW.geometry()), {'min': 0, 'max': 1, 'palette': ['42762f', 'ffffff']}, 'Combined Classification')\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f64ZabF7Avtu"
      },
      "source": [
        "6.1.7 - Validation and accuracy assessment for each of the 3 classifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkstm3sWWQkH"
      },
      "outputs": [],
      "source": [
        "# Validation function\n",
        "def valid_habitat(number):\n",
        "  def wrap(feature):\n",
        "    return feature.setMulti(ee.Dictionary.fromLists(['habitat'], [number]))\n",
        "  return wrap\n",
        "\n",
        "## Validation data\n",
        "v_seagrass = v_seagrass_pre.map(valid_habitat(seagrass_class))\n",
        "v_nonSeagrass = v_nonSeagrass_pre.map(valid_habitat(nonSeagrass_class))\n",
        "v_FC = v_seagrass.merge(v_nonSeagrass)\n",
        "v_FC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWObll4oURfn"
      },
      "outputs": [],
      "source": [
        "# Collect sampled features from each image\n",
        "def validation(image):\n",
        "    # Buffer the validation points by 10 meters (optional, keep if desired)\n",
        "   # buffered_v_FC = v_FC.map(lambda feature: feature.buffer(5))\n",
        "\n",
        "    sampled = image.sampleRegions(\n",
        "        collection=v_FC,\n",
        "        properties=['habitat'],\n",
        "        scale=3\n",
        "        )\n",
        "    return sampled\n",
        "\n",
        "\n",
        "# Map the sampling function and convert result to a list of FeatureCollections\n",
        "sampled_v_list = validation(soft_map_th)\n",
        "\n",
        "# Flatten the FeatureCollections into one big FeatureCollection\n",
        "sampledValidation_pre = ee.FeatureCollection(sampled_v_list) #.filter(ee.Filter.notNull(['habitat']))\n",
        "\n",
        "## To validate with the final combination of the 3 classifications (this will be better)\n",
        "# sampledValidation_pre = final_classification_pre.sampleRegions(\n",
        "#     collection=v_FC,\n",
        "#     scale=3,\n",
        "#     properties=['habitat'])\n",
        "\n",
        "# Using sampleRegions we take values across the Image Collection. getting valid FeatureCollection when overlapping with pixels\n",
        "print('sampled Validation:', sampledValidation_pre.size().getInfo())\n",
        "sampledValidation_pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3bbR77kcVHf"
      },
      "outputs": [],
      "source": [
        "errorMatrix = sampledValidation_pre.errorMatrix('habitat', 'classification')\n",
        "print('Confusion Matrix:', errorMatrix.getInfo())\n",
        "\n",
        "# Get confusion matrix data as a list of lists\n",
        "confusion_matrix_data = errorMatrix.array().getInfo()\n",
        "\n",
        "# Convert the list to a NumPy array\n",
        "matrix_values = np.array(confusion_matrix_data)  # Convert to NumPy array\n",
        "\n",
        "# Define class labels\n",
        "class_names = ['seagrass', 'nonSeagrass']  # Adjust if your class names are different\n",
        "\n",
        "# Create ConfusionMatrixDisplay object\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=matrix_values, display_labels=class_names)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel(\"EO prediction\", fontsize = 14)  # Change to your desired text\n",
        "plt.ylabel(\"In situ data\", fontsize = 14)\n",
        "disp.ax_.tick_params(axis='both', which='major', labelsize=18)  # Increase axis tick label size  # Change to your desired text\n",
        "plt.show()\n",
        "\n",
        "# Print accuracy metrics\n",
        "overall_accuracy = errorMatrix.accuracy().getInfo()\n",
        "print('Overall Accuracy:', overall_accuracy)\n",
        "producers_accuracy = ee.Array(errorMatrix.producersAccuracy()).reshape([-1]).getInfo()\n",
        "print('PA:', producers_accuracy)\n",
        "users_accuracy = ee.Array(errorMatrix.consumersAccuracy()).reshape([-1]).getInfo()\n",
        "print('UA:', users_accuracy)\n",
        "\n",
        "# Calcuate F1-score\n",
        "# Extract the components from the confusion matrix\n",
        "truePositives = errorMatrix.array().get([0, 0])\n",
        "falsePositives = errorMatrix.array().get([1, 0])\n",
        "falseNegatives = errorMatrix.array().get([0, 1])\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision = truePositives.divide(truePositives.add(falsePositives))\n",
        "recall = truePositives.divide(truePositives.add(falseNegatives))\n",
        "f1_score = ee.Number(2).multiply(precision.multiply(recall)).divide(precision.add(recall))\n",
        "\n",
        "print('F1-score:', f1_score.getInfo())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONf8Gn5zKk77"
      },
      "source": [
        "### Area quantification and +-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lqZtQPIKluI"
      },
      "outputs": [],
      "source": [
        "# Mask seagrass pixels\n",
        "seagrass_pre = classification_images_pre.eq(0)\n",
        "\n",
        "# create a binary mask: 1 = seagrass, 0 = not\n",
        "seagrass_mask = seagrass_pre.rename('seagrass')  # change eq(0) if your seagrass label differs\n",
        "\n",
        "# count seagrass pixels (sum of 1s)\n",
        "pixel_count = seagrass_mask.reduceRegion(\n",
        "    reducer=ee.Reducer.sum(),\n",
        "    geometry=OSW.geometry(),\n",
        "    scale=3, # 3 m pixels\n",
        "    maxPixels=1e13\n",
        ").get('seagrass').getInfo()\n",
        "\n",
        "# convert to hectares: each pixel = 9 m2 -> 9/10000 = 0.0009 ha\n",
        "area_ha_pre = pixel_count * 9.0 / 10000.0\n",
        "\n",
        "print(f\"Seagrass pixels: {pixel_count}, area: {area_ha_pre} ha\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5675ZQsFK9fv"
      },
      "outputs": [],
      "source": [
        "# Scale probabilities from 0-100 to 0-1\n",
        "probabilities_pre = probabilities.divide(100).select('seagrass')\n",
        "\n",
        "# Get the mean probability of seagrass over the region of interest\n",
        "mean_sum_prob_seagrass_pre = probabilities_pre.reduceRegion(\n",
        "    reducer=ee.Reducer.mean(),\n",
        "    geometry=OSW.geometry(),\n",
        "    scale=3, # Use the same scale as the area calculation\n",
        "    maxPixels=1e13\n",
        ").get('seagrass') # Get the mean value for the 'seagrass' band\n",
        "\n",
        "overall_accuracy_pre = ee.Number(overall_accuracy) # Use the overall_accuracy from the pre-event validation cell\n",
        "\n",
        "# Get the total seagrass area for the pre-event classification (assuming it's stored in area_ha variable from cell ZfHt_UQ49oKf)\n",
        "# If not, you might need to recalculate it here or fetch it from the appropriate variable.\n",
        "total_seagrass_area_pre = ee.Number(area_ha_pre)\n",
        "\n",
        "# Calculate uncertainty for the pre-event seagrass area using the provided formula:\n",
        "# uncertainty = area * Overall Accuracy * (3 - mean of the sum of the probabilities predicted as seagrass) / 3\n",
        "# Assuming '3' is the number of images used in the pre-event period (sentinel2_l1c_pre has 3 images)\n",
        "num_images_pre = ee.Number(1) # Set the number of pre-event images to 1 as an Earth Engine Number\n",
        "\n",
        "uncertainty_pre_seagrass_area = total_seagrass_area_pre.multiply(overall_accuracy_pre).multiply(num_images_pre.subtract(mean_sum_prob_seagrass_pre)).divide(num_images_pre)\n",
        "\n",
        "print(f\"Uncertainty of pre-event seagrass area: {area_ha_pre:.2f} +- {uncertainty_pre_seagrass_area.getInfo():.2f} ha\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0569l3h78ia"
      },
      "source": [
        "6.1.8 - Uncertainty analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-rgS_YS38TS"
      },
      "outputs": [],
      "source": [
        "# ## To run uncertainties in the first classification (pre-event, 2018)\n",
        "# ## t=(9*OA*(3-median probabilities))/3\n",
        "# # 9 = area of pixel in square meters (3x3)\n",
        "# # 3 = number of images\n",
        "\n",
        "# ## first scale probabilities to 0-1 values\n",
        "# def scale_to_unit(image):\n",
        "#     return image.divide(100).copyProperties(image, image.propertyNames())\n",
        "\n",
        "# # Apply the scaling function to the collection\n",
        "# probabilities_01 = probabilities.map(scale_to_unit)\n",
        "\n",
        "# median_probability = probabilities_01.select('seagrass').median().rename('seagrass_median_prob')\n",
        "# median_probability\n",
        "\n",
        "# # Select the band containing median probability\n",
        "# median_probability = median_probability.select('seagrass_median_prob')\n",
        "\n",
        "# # Apply the formula:\n",
        "# # uncertainty = (9 * overall_accuracy * (3 - median_probability)) / 3\n",
        "# three = ee.Number(3)\n",
        "# nine = ee.Number(9)\n",
        "# oa = ee.Number(overall_accuracy)\n",
        "\n",
        "# # Compute: (3 - median_prob)\n",
        "# diff = ee.Image.constant().subtract(median_probability)\n",
        "\n",
        "# # Continue: (9 * overall_accuracy * diff) / 3\n",
        "# # uncertainty = (diff.multiply(oa).multiply(nine)).divide(three)\n",
        "# uncertainty = diff.divide(oa)\n",
        "\n",
        "# # Add the uncertainty as a new band\n",
        "# uncertainty_pre = image.addBands(uncertainty.rename('uncertainty'))\n",
        "\n",
        "# region = uncertainty_pre.geometry()\n",
        "# # Calculate min and max of the uncertainty band\n",
        "# stats = uncertainty_pre.select('uncertainty').reduceRegion(\n",
        "#     reducer=ee.Reducer.minMax(),\n",
        "#     geometry=region,\n",
        "#     scale=3,\n",
        "#     maxPixels=1e9\n",
        "# )\n",
        "\n",
        "# # Get the results\n",
        "# min_val = stats.get('uncertainty_min').getInfo()\n",
        "# max_val = stats.get('uncertainty_max').getInfo()\n",
        "\n",
        "# print('Uncertainty range:', min_val, 'to', max_val)\n",
        "\n",
        "\n",
        "# # ###########################\n",
        "\n",
        "# # Select the uncertainty band\n",
        "# uncertainty_pre = uncertainty_pre.select('uncertainty')\n",
        "\n",
        "# # Normalize to 0â1\n",
        "# normalized_uncertainty = uncertainty.subtract(min_val).divide(max_val - min_val)\n",
        "\n",
        "# # Add it back to the image\n",
        "# overlap_mask = combined_classification_pre.mask().reduce(ee.Reducer.anyNonZero())\n",
        "# uncertainty_pre_norm = image.addBands(normalized_uncertainty.rename('uncertainty_norm'))\n",
        "\n",
        "# region = uncertainty_pre_norm.geometry()\n",
        "# # Calculate min and max of the uncertainty band\n",
        "# stats2 = uncertainty_pre_norm.select('uncertainty_norm').reduceRegion(\n",
        "#     reducer=ee.Reducer.minMax(),\n",
        "#     geometry=region,\n",
        "#     scale=3,\n",
        "#     maxPixels=1e9\n",
        "# )\n",
        "\n",
        "# # Get the results\n",
        "# min_val = stats2.get('uncertainty_norm_min').getInfo()\n",
        "# max_val = stats2.get('uncertainty_norm_max').getInfo()\n",
        "\n",
        "# print('Uncertainty range norm:', min_val, 'to', max_val)\n",
        "\n",
        "# # Visualize the mean uncertainty layer\n",
        "# # Define visualization parameters for the uncertainty band\n",
        "# # You may need to adjust the min/max values based on your data range\n",
        "# vis_params = {'bands': ['uncertainty_norm'], 'palette': ['#4d004b', '#4f004d', '#50014e', '#520150', '#540251', '#550253', '#570354', '#580356', '#5a0457', '#5c0459', '#5d055a', '#5f055c', '#61065d', '#62065f', '#640761', '#650762', '#670864', '#690865', '#6a0867', '#6c0968', '#6e096a', '#6f0a6b', '#710a6d', '#730b6e', '#740b70', '#760c71', '#770c73', '#790d75', '#7b0d76', '#7c0e78', '#7e0e79', '#800f7b', '#810f7c', '#81117d', '#81127e', '#82147f', '#821580', '#821781', '#821982', '#831a83', '#831c84', '#831d85', '#831f86', '#832088', '#842289', '#84248a', '#84258b', '#84278c', '#85288d', '#852a8e', '#852b8f', '#852d90', '#852f91', '#863092', '#863293', '#863394', '#863595', '#873696', '#873897', '#873a98', '#873b99', '#873d9a', '#883e9b', '#88409c', '#88419d', '#88439e', '#88449e', '#88459f', '#8947a0', '#8948a0', '#8949a1', '#894ba2', '#894ca2', '#894da3', '#894fa3', '#8950a4', '#8a51a5', '#8a52a5', '#8a54a6', '#8a55a7', '#8a56a7', '#8a58a8', '#8a59a8', '#8a5aa9', '#8b5caa', '#8b5daa', '#8b5eab', '#8b60ac', '#8b61ac', '#8b62ad', '#8b64ad', '#8b65ae', '#8c66af', '#8c68af', '#8c69b0', '#8c6ab1', '#8c6cb1', '#8c6db2', '#8c6eb3', '#8c70b3', '#8c71b4', '#8c72b5', '#8c74b5', '#8c75b6', '#8c76b7', '#8c78b7', '#8c79b8', '#8c7ab8', '#8c7cb9', '#8c7dba', '#8c7eba', '#8c80bb', '#8c81bc', '#8c82bc', '#8c84bd', '#8c85be', '#8c86be', '#8c88bf', '#8c89c0', '#8c8bc0', '#8c8cc1', '#8c8dc2', '#8c8fc2', '#8c90c3', '#8c91c4', '#8c93c4', '#8c94c5', '#8c95c6', '#8c97c6', '#8d98c7', '#8d99c8', '#8e9ac8', '#8f9bc9', '#8f9dc9', '#909eca', '#909fcb', '#91a0cb', '#91a1cc', '#92a3cd', '#92a4cd', '#93a5ce', '#94a6ce', '#94a7cf', '#95a8d0', '#95aad0', '#96abd1', '#96acd2', '#97add2', '#98aed3', '#98b0d3', '#99b1d4', '#99b2d5', '#9ab3d5', '#9ab4d6', '#9bb6d7', '#9cb7d7', '#9cb8d8', '#9db9d9', '#9dbad9', '#9ebcda', '#9fbcda', '#a0bddb', '#a1bedb', '#a2bfdb', '#a3bfdc', '#a4c0dc', '#a5c1dc', '#a6c2dd', '#a7c2dd', '#a8c3de', '#a9c4de', '#aac4de', '#abc5df', '#acc6df', '#adc7e0', '#aec7e0', '#afc8e0', '#b0c9e1', '#b1c9e1', '#b2cae1', '#b3cbe2', '#b4cce2', '#b5cce3', '#b6cde3', '#b7cee3', '#b9cee4', '#bacfe4', '#bbd0e4', '#bcd1e5', '#bdd1e5', '#bed2e6', '#bfd3e6', '#c0d4e6', '#c1d4e7', '#c2d5e7', '#c3d6e8', '#c4d7e8', '#c5d8e9', '#c6d8e9', '#c7d9e9', '#c8daea', '#c9dbea', '#cadbeb', '#cbdceb', '#ccddec', '#cddeec', '#cedfec', '#cfdfed', '#d0e0ed', '#d1e1ee', '#d2e2ee', '#d3e2ef', '#d4e3ef', '#d6e4f0', '#d7e5f0', '#d8e6f0', '#d9e6f1', '#dae7f1', '#dbe8f2', '#dce9f2', '#ddeaf3', '#deeaf3', '#dfebf4', '#e0ecf4', '#e1ecf4', '#e1edf5', '#e2edf5', '#e3eef5', '#e4eef5', '#e4eff6', '#e5eff6', '#e6f0f6', '#e6f0f7', '#e7f1f7', '#e8f1f7', '#e9f2f7', '#e9f2f8', '#eaf3f8', '#ebf3f8', '#ebf4f8', '#ecf4f9', '#edf5f9', '#eef5f9', '#eef6fa', '#eff6fa', '#f0f7fa', '#f1f7fa', '#f1f8fb', '#f2f8fb', '#f3f9fb', '#f3f9fc', '#f4fafc', '#f5fafc', '#f6fbfc', '#f6fbfd', '#f7fcfd'], 'min': 0, 'max': 1}\n",
        "# Map = geemap.Map()\n",
        "# Map.addLayer(uncertainty_pre_norm.select('uncertainty_norm'), vis_params, \"Uncertainty Pre-event\")\n",
        "# Map.centerObject(OSW, 13)\n",
        "# Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RFucqb2i5el"
      },
      "outputs": [],
      "source": [
        "# # Export the FeatureCollection to Google Drive\n",
        "# task = ee.batch.Export.image.toDrive(\n",
        "#     image=uncertainty_pre_norm.toFloat(),\n",
        "#     description='uncertainty_pre_norm',  # Description for the task\n",
        "#     folder='Colab_Notebooks/export',\n",
        "#     region = OSW.geometry(),\n",
        "#     scale=3,  # Adjust the scale as needed\n",
        "#     fileFormat='GeoTIFF'  # Choose your desired file format (CSV, GeoJSON, KML, SHP, TFRecord)\n",
        "# )\n",
        "\n",
        "# # Start the export task\n",
        "# task.start()\n",
        "\n",
        "# print('Export task started. You can monitor its progress in the \"Tasks\" tab.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRMNsPGGEauF"
      },
      "outputs": [],
      "source": [
        "# ## Calculate uncertainty\n",
        "# # probability IC: probabilities\n",
        "# # classified IC: classification_images_pre\n",
        "# # validation pre: v_FC\n",
        "\n",
        "# def calculate_uncertainty(prob_image, classified_image, validation_fc):\n",
        "#     # Get the probability bands from the probability image\n",
        "#     probabilities_image = prob_image.select(['seagrass', 'nonSeagrass'])\n",
        "\n",
        "#     # Sample the classified image with validation points\n",
        "#     validated = classified_image.sampleRegions(\n",
        "#         collection=validation_fc, # Using the provided validation FeatureCollection\n",
        "#         properties=['habitat'], # Assuming 'habitat' is the class property in v_FC\n",
        "#         scale=3,\n",
        "#         geometries=True\n",
        "#     )\n",
        "\n",
        "#     # Calculate overall accuracy if there are enough validation points\n",
        "#     overall_accuracy = ee.Algorithms.If(\n",
        "#         validated.size().gt(1),\n",
        "#         validated.errorMatrix('habitat', 'classification').accuracy(),\n",
        "#         ee.Number(1.0) # Default accuracy if not enough points\n",
        "#     )\n",
        "\n",
        "#     # Ensure overall_accuracy is treated as an Earth Engine Number\n",
        "#     overall_accuracy = ee.Number(overall_accuracy)\n",
        "\n",
        "#     # Calculate uncertainty per pixel: (1 - Probability of Seagrass) / Overall Accuracy\n",
        "#     # Ensure overall_accuracy is treated as a constant image for pixel-wise division\n",
        "#     overall_accuracy_image = ee.Image.constant(overall_accuracy).float()\n",
        "\n",
        "#     # Calculate the uncertainty based on seagrass probability\n",
        "#     # Lower probability of seagrass indicates higher uncertainty for seagrass class\n",
        "#     # A common approach is 1 - probability or using entropy. Let's use 1 - probability as a simple measure.\n",
        "#     uncertainty_prob = probabilities_image.select('seagrass').multiply(-1).add(1).rename('uncertainty_prob')\n",
        "\n",
        "#     # You could also consider scaling by accuracy, e.g., uncertainty_prob / overall_accuracy\n",
        "#     uncertainty = uncertainty_prob.divide(overall_accuracy_image).rename('uncertainty')\n",
        "\n",
        "#     # Return the uncertainty band, aligning it with the classified image properties\n",
        "#     return classified_image.addBands(uncertainty).copyProperties(classified_image, classified_image.propertyNames())\n",
        "\n",
        "\n",
        "# # Apply the function to your ImageCollections\n",
        "# # We need to iterate through one collection (e.g., classification_images_pre) and find the corresponding image in the other (probabilities)\n",
        "# def map_uncertainty_calculation(classified_image):\n",
        "#     # Find the corresponding probability image using the system:index\n",
        "#     prob_image = probabilities.filter(ee.Filter.eq('system:index', classified_image.get('system:index'))).first()\n",
        "\n",
        "#     # Calculate uncertainty for this image pair\n",
        "#     return calculate_uncertainty(prob_image, classified_image, v_FC)\n",
        "\n",
        "\n",
        "# # Assuming 'classification_images_pre' is your pre-event ImageCollection containing the 'classification' band\n",
        "# # Assuming 'probabilities' is your pre-event ImageCollection containing 'seagrass' and 'nonSeagrass' bands\n",
        "# # Assuming 'v_FC' is your FeatureCollection of validation points (pre-event validation data)\n",
        "\n",
        "# uncertainty_images_pre = soft_map.map(map_uncertainty_calculation())\n",
        "\n",
        "# # You can now visualize or export the 'uncertainty' band from the uncertainty_images_pre collection\n",
        "# print('Uncertainty calculation added to pre-event images.')\n",
        "\n",
        "# # uncertainty_images_pre_mean = uncertainty_images_pre.mean()\n",
        "# # uncertainty_images_pre_mean\n",
        "\n",
        "# uncertainty_images_pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RV8sZjcRxr3L"
      },
      "outputs": [],
      "source": [
        "# # Display the combined classification\n",
        "# Map.addLayer(uncertainty_images_pre.first().select('uncertainty'), {'min': 0, 'max': 1, 'palette': ['42762f', '7cb75a', 'e2e9ab', 'ffffff']}, 'Uncertainty')\n",
        "# Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73YN-trEvpKp"
      },
      "source": [
        "## 6.2 - Post-event Multi-sensor Image Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uu5k8BKDQ7ji"
      },
      "outputs": [],
      "source": [
        "# Binary classification setup\n",
        "seagrass_class = 0\n",
        "nonSeagrass_class = 1\n",
        "\n",
        "# Classification and validation parameters\n",
        "trees = 50\n",
        "t = 45\n",
        "\n",
        "# Boxcar kernel: a square matrix where all values are equal, and it calculates the mean of the pixel values within that square neighborhood.\n",
        "boxcar = ee.Kernel.square(radius=2, units='pixels', normalize=True)\n",
        "bands = multi_sensor_post.bandNames()\n",
        "# print(bands.getInfo())\n",
        "\n",
        "def boxcar_image(image):\n",
        "    return image.convolve(boxcar)\n",
        "\n",
        "# Apply the function to every image in the collection\n",
        "classificationComp_post = boxcar_image(multi_sensor_post)\n",
        "classificationComp_post"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4ETaRlTRH9R"
      },
      "source": [
        "#### 6.2.1 - Prepare training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICvx1UFBRmKZ"
      },
      "outputs": [],
      "source": [
        "# Training data - class property recoding and merging - MODEL 2 (POST-EVENT)\n",
        "t_seagrass = t_seagrass_post.map(lambda x: x.setMulti(ee.Dictionary.fromLists(['habitat'], [seagrass_class])))\n",
        "t_nonSeagrass = t_nonSeagrass_post.map(lambda x: x.setMulti(ee.Dictionary.fromLists(['habitat'], [nonSeagrass_class])))\n",
        "t_FC = t_seagrass.merge(t_nonSeagrass)\n",
        "\n",
        "\n",
        "# Collect sampled features from each image\n",
        "def sample_image(image):\n",
        "    sampled = image.sampleRegions(\n",
        "        collection=t_FC,\n",
        "        scale=3,\n",
        "        geometries=True\n",
        "    ).filter(ee.Filter.notNull(bands))\n",
        "\n",
        "    return sampled\n",
        "\n",
        "# Flatten the FeatureCollections into one big FeatureCollection\n",
        "sampledData = sample_image(classificationComp_post)\n",
        "\n",
        "# Using sampleRegions we take values across the Image Collection. getting valid FeatureCollection when overlapping with pixels\n",
        "print('sampledData:', sampledData.size().getInfo())\n",
        "print('t_FC:', t_FC.size().getInfo())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alSxDTlUSv8T"
      },
      "source": [
        "#### 6.2.2 - Extract probabilities for each class and train classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AInGyhZZTF7z"
      },
      "outputs": [],
      "source": [
        "## To extract feature importance and evaluate\n",
        "def soft_prob_subfn(image, num):\n",
        "       training = sampledData.map(lambda ft: ft.set(\n",
        "        'prob',\n",
        "        ee.Algorithms.If(ft.getNumber('habitat').eq(num), 1, 0)\n",
        "        ))\n",
        "\n",
        "       trained = ee.Classifier.smileRandomForest(numberOfTrees=trees) \\\n",
        "           .train(training, 'prob', image.bandNames()) \\\n",
        "           .setOutputMode('PROBABILITY')\n",
        "\n",
        "       dict_classifier = trained.explain()\n",
        "\n",
        "       # Create a Feature with the dictionary as a property\n",
        "       feature = ee.Feature(None, {'classifier_explanation': dict_classifier})\n",
        "\n",
        "       # Classify and convert to percentage scale\n",
        "       classified = image.classify(trained).multiply(100).toInt8()\n",
        "\n",
        "       # Return both the classified image and the Feature with explanation\n",
        "       return ee.Image(classified).set('classifier_explanation', feature)\n",
        "\n",
        "# Apply the function to the single image\n",
        "seagrass_prob_image = soft_prob_subfn(classificationComp_post, seagrass_class)\n",
        "nonSeagrass_prob_image = soft_prob_subfn(classificationComp_post, nonSeagrass_class)\n",
        "\n",
        "seagrass_prob_image\n",
        "\n",
        "# # Initialize an empty dictionary to store feature importances\n",
        "# mean_importance = {}\n",
        "\n",
        "# # Iterate through the first three images\n",
        "# for i in range(3):\n",
        "#   image = ee.Image(first_three_images.get(i))\n",
        "#   classifier_explanation = image.get('classifier_explanation').getInfo()['properties']['classifier_explanation']\n",
        "#   importance_dict = classifier_explanation.get('importance')\n",
        "\n",
        "#   # Accumulate feature importances\n",
        "#   for feature, importance in importance_dict.items():\n",
        "#     mean_importance[feature] = mean_importance.get(feature, 0) + importance\n",
        "\n",
        "# # Calculate the mean feature importance\n",
        "# for feature in mean_importance:\n",
        "#   mean_importance[feature] /= 3\n",
        "\n",
        "# # Print the mean feature importance\n",
        "# print(mean_importance)\n",
        "\n",
        "# # Sort features by importance in descending order\n",
        "# sorted_importance = dict(sorted(mean_importance.items(), key=lambda item: item[1], reverse=False))\n",
        "\n",
        "# # Extract feature names and importance values\n",
        "# feature_names = list(sorted_importance.keys())\n",
        "# importance_values = list(sorted_importance.values())\n",
        "\n",
        "# # Create a list of colors based on feature name prefix\n",
        "# colors = ['#005b96' if name.startswith('PS_') else '#6497b1' for name in feature_names]\n",
        "\n",
        "# # Create the horizontal bar graph (switched axes)\n",
        "# plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n",
        "# plt.barh(feature_names, importance_values, color=colors) # Changed to barh for horizontal bars\n",
        "# plt.ylabel(\"Features\") # Switched x and y labels\n",
        "# plt.xlabel(\"Importance\") # Switched x and y labels\n",
        "# plt.title(\"Feature Importance (2024)\")\n",
        "# # plt.axvline(x=4.2, linestyle='dotted', color='grey')  # Add dotted vertical line\n",
        "# plt.show()  # Display the plot\n",
        "# plt.tight_layout()\n",
        "\n",
        "# selected_bands = [band for band, importance in mean_importance.items() if importance >= 0] ## Use only selected bands for the classification ##4.2 before\n",
        "\n",
        "# print(\"Selected bands:\", selected_bands)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUXO4j2mAJVT"
      },
      "outputs": [],
      "source": [
        "## Co-variance analysis\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "selected_bands = classificationComp_post.bandNames()\n",
        "\n",
        "# Function to extract band values from a FeatureCollection\n",
        "def extract_band_values(feature_collection, bands):\n",
        "    data = feature_collection.toList(feature_collection.size()).map(lambda feature: ee.Feature(feature).toDictionary().select(bands)).getInfo()\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "# Extract band values for selected bands\n",
        "band_values_df = extract_band_values(sampledData, selected_bands)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = band_values_df.corr()\n",
        "\n",
        "# Create a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(correlation_matrix, bool), k=1)\n",
        "\n",
        "# Apply the mask to the filtered correlation matrix\n",
        "filtered_correlation_matrix = correlation_matrix.mask(mask)\n",
        "filtered_correlation_matrix = filtered_correlation_matrix[np.abs(correlation_matrix) > 0.80]\n",
        "\n",
        "# Get bands with at least one correlation above 0.9\n",
        "bands_to_keep = filtered_correlation_matrix.columns[filtered_correlation_matrix.any()]\n",
        "\n",
        "# Filter the original correlation matrix to keep only relevant bands\n",
        "filtered_correlation_matrix = correlation_matrix.loc[bands_to_keep, bands_to_keep]\n",
        "\n",
        "# Plot only the lower triangle of the correlation matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(filtered_correlation_matrix, mask=mask, annot=True, cmap='coolwarm',\n",
        "            fmt=\".2f\", linewidths=.5, linecolor='lightgrey', square=True,\n",
        "            cbar_kws={\"shrink\": .75})\n",
        "plt.title('Band Covariability Analysis')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Bands to keep:\", bands_to_keep.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsF4SE91mO6N"
      },
      "outputs": [],
      "source": [
        "# #### REMOVE BANDS THAT ARE NOT USEFUL\n",
        "\n",
        "# # Define the bands to remove\n",
        "# bands_to_remove = ['PS_B8', 'S2_B8', 'S2_B6'] # 'PS_Kd_505', 'S2_B6', 'S2_B7', 'S2_B8',\n",
        "\n",
        "# # Create a list of bands to keep by filtering out the bands to remove\n",
        "# selected_bands = [band for band in selected_bands if band not in bands_to_remove]\n",
        "\n",
        "# # Apply the select method to the Image Collection to keep the desired bands\n",
        "# classificationComp_post = classificationComp_post.select(selected_bands)\n",
        "# classificationComp_post.first().bandNames()\n",
        "# classificationComp_post"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7vpsYmmAVq_"
      },
      "source": [
        "### 6.2.3 - Generate probability layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL1u5RSWAYKE"
      },
      "outputs": [],
      "source": [
        "## Train classifier and display probability map for seagrasses\n",
        "# Define classes dictionary\n",
        "classes = {\n",
        "  'classes_values': [seagrass_class, nonSeagrass_class],\n",
        "  'classes_names': ['seagrass','nonSeagrass']\n",
        "}\n",
        "\n",
        "classes\n",
        "\n",
        "# Assume this is already defined:\n",
        "# - classificationComp_pre: an ImageCollection\n",
        "# - classes: dictionary with class values and names\n",
        "# - soft_prob_subfn(image, class_id): returns a probability image for one class\n",
        "\n",
        "def classify_with_all_classes(image):\n",
        "    # Classify image for each class and rename the result accordingly\n",
        "    classified_images = ee.List(classes['classes_values']).map(\n",
        "        lambda class_id: soft_prob_subfn(image, class_id)\n",
        "    )\n",
        "\n",
        "    # Convert list of images into one multi-band image (each class as band)\n",
        "    classified_combined = ee.ImageCollection(classified_images).toBands()\n",
        "    classified_combined = classified_combined.rename(classes['classes_names'])\n",
        "\n",
        "    # Preserve metadata if needed\n",
        "    return classified_combined.copyProperties(image, image.propertyNames())\n",
        "\n",
        "# Generate probabilities in the ImageCollection\n",
        "probabilities = classify_with_all_classes(classificationComp_post)\n",
        "probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMhgfl_IAqVR"
      },
      "outputs": [],
      "source": [
        "# Visualize probabilities\n",
        "probabilities = ee.Image(probabilities).clip(OSW).updateMask(land_mask)\n",
        "Map = geemap.Map()\n",
        "Map.addLayer(probabilities.select('seagrass'), {'min': 45, 'max': 100}, 'Seagrass Prob')\n",
        "Map.addLayer(probabilities.select('nonSeagrass'), {'min': 45, 'max': 100}, 'NonSeagrass Prob')\n",
        "Map.centerObject(probabilities, zoom=12)\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IaIhvZdA57j"
      },
      "source": [
        "#### 6.2.4 - Threshold classes based on probabilities and classify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQcO9zFYA6ue"
      },
      "outputs": [],
      "source": [
        "# Based on the generated probabilities, apply thresholding for seagrass and nonSeagrass on the whole Image Collection\n",
        "\n",
        "# Threshold function for seagrass\n",
        "def threshold_seagrass(image):\n",
        "    return image.select('seagrass').updateMask(image.select('seagrass').gt(t)) \\\n",
        "        .copyProperties(image, image.propertyNames())\n",
        "\n",
        "# Threshold function for non-seagrass\n",
        "def threshold_non_seagrass(image):\n",
        "    return image.select('nonSeagrass').updateMask(image.select('nonSeagrass').gt(t)) \\\n",
        "        .copyProperties(image, image.propertyNames())\n",
        "\n",
        "# Map the thresholding over the probabilities collection\n",
        "seagrass_soft = threshold_seagrass(probabilities)\n",
        "nonSeagrass_soft = threshold_non_seagrass(probabilities)\n",
        "\n",
        "# Combine the thresholded images into a single image (taking the first image from each collection as an example)\n",
        "# If you intend to process all images in the collection, the downstream code needs to be adapted to work with ImageCollections.\n",
        "soft_map = ee.Image(seagrass_soft).addBands(ee.Image(nonSeagrass_soft))\n",
        "soft_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEEXi_o5BQeA"
      },
      "source": [
        "#### 6.2.5 - Perform classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBgfKy7xBTIj"
      },
      "outputs": [],
      "source": [
        "def soft_to_hard(image):\n",
        "    seagrass = image.select('seagrass')\n",
        "    non_seagrass = image.select('nonSeagrass')\n",
        "    prob_aoi = ee.Image(probabilities).geometry()\n",
        "\n",
        "    classified = (ee.Image.constant(2)\n",
        "        .where(seagrass.gte(t), ee.Number(0).add(1))  # temporary +1 to mask 0s\n",
        "        .where(non_seagrass.gte(t), ee.Number(1).add(1))\n",
        "        .selfMask()\n",
        "        .subtract(1)  # back to 0 and 1\n",
        "        .rename('classification')\n",
        "        .clip(prob_aoi))\n",
        "    return classified\n",
        "\n",
        "# Apply to soft_map\n",
        "soft_map_th = soft_to_hard(soft_map)\n",
        "soft_map_th"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXt9RFUYBbv0"
      },
      "source": [
        "#### 6.2.6 - Combine the three classifications for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IOSgVQABdfg"
      },
      "outputs": [],
      "source": [
        "# 1. Extract the 'classification' band from each image\n",
        "classification_images_post = soft_map_th.select('classification').mask(land_mask).clip(OSW)\n",
        "\n",
        "# Display the combined classification\n",
        "Map.addLayer(classification_images_post, {'min': 0, 'max': 1, 'palette': ['42762f', '7cb75a', 'e2e9ab', 'ffffff']}, 'Combined Classification')\n",
        "Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psE8WRprrPkZ"
      },
      "outputs": [],
      "source": [
        "# # Export the FeatureCollection to Google Drive\n",
        "# task = ee.batch.Export.image.toDrive(\n",
        "#     image=combined_classification_post,\n",
        "#     description='combined_classification_post',  # Description for the task\n",
        "#     folder='Colab_Notebooks/export',\n",
        "#     region = OSW.geometry(),\n",
        "#     scale=3,  # Adjust the scale as needed\n",
        "#     fileFormat='GeoTIFF'  # Choose your desired file format (CSV, GeoJSON, KML, SHP, TFRecord)\n",
        "# )\n",
        "\n",
        "# # Start the export task\n",
        "# task.start()\n",
        "\n",
        "# print('Export task started. You can monitor its progress in the \"Tasks\" tab.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMX-s1IbIACl"
      },
      "outputs": [],
      "source": [
        "# Apply conditional classification for obtain the final binary map\n",
        "classification_images_post = classification_images_post.expression(\n",
        "    'b(0) < 0.35 ? 0 : 1',  # Conditional expression\n",
        "    {'classification': classification_images_post}  # Band name mapping\n",
        ").rename('classification')  # Rename the band\n",
        "\n",
        "# Display the combined classification\n",
        "Map.addLayer(classification_images_post.mask(land_mask).clip(OSW.geometry()), {'min': 0, 'max': 1, 'palette': ['42762f', 'ffffff']}, 'Combined Classification')\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnb-3cgaCDuK"
      },
      "source": [
        "#### 6.2.7 - Validation and accuracy assessment for each of the 3 classifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9upFEQXFCFdJ"
      },
      "outputs": [],
      "source": [
        "# Validation function\n",
        "def valid_habitat(number):\n",
        "  def wrap(feature):\n",
        "    return feature.setMulti(ee.Dictionary.fromLists(['habitat'], [number]))\n",
        "  return wrap\n",
        "\n",
        "## Validation data\n",
        "v_seagrass = v_seagrass_post.map(valid_habitat(seagrass_class))\n",
        "v_nonSeagrass = v_nonSeagrass_post.map(valid_habitat(nonSeagrass_class))\n",
        "v_FC = v_seagrass.merge(v_nonSeagrass)\n",
        "v_FC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPcjG7IYJueg"
      },
      "outputs": [],
      "source": [
        "## To validate with the final combination of the 3 classifications (this will be better)\n",
        "# sampledValidation_post = final_classification_post.sampleRegions(\n",
        "#     collection=v_FC,\n",
        "#     scale=3,\n",
        "#     properties=['habitat'])\n",
        "\n",
        "# sampledValidation_post"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bKSqFQRDWSB"
      },
      "outputs": [],
      "source": [
        "# Collect sampled features from each image\n",
        "def validation(image):\n",
        "    # Buffer the validation points by 10 meters (optional, keep if desired)\n",
        "   # buffered_v_FC = v_FC.map(lambda feature: feature.buffer(5))\n",
        "\n",
        "    sampled = image.sampleRegions(\n",
        "        collection=v_FC,\n",
        "        properties=['habitat'],\n",
        "        scale=3\n",
        "        )\n",
        "    return sampled\n",
        "\n",
        "\n",
        "# Map the sampling function and convert result to a list of FeatureCollections\n",
        "sampled_v_list = validation(soft_map_th)\n",
        "\n",
        "# Flatten the FeatureCollections into one big FeatureCollection\n",
        "sampledValidation_post = ee.FeatureCollection(sampled_v_list) #.filter(ee.Filter.notNull(['habitat']))\n",
        "\n",
        "## To validate with the final combination of the 3 classifications (this will be better)\n",
        "# sampledValidation_pre = final_classification_pre.sampleRegions(\n",
        "#     collection=v_FC,\n",
        "#     scale=3,\n",
        "#     properties=['habitat'])\n",
        "\n",
        "# Using sampleRegions we take values across the Image Collection. getting valid FeatureCollection when overlapping with pixels\n",
        "print('sampled Validation:', sampledValidation_post.size().getInfo())\n",
        "sampledValidation_post"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8b2ttAvDhOd"
      },
      "outputs": [],
      "source": [
        "errorMatrix = sampledValidation_post.errorMatrix('habitat', 'classification')\n",
        "print('Confusion Matrix:', errorMatrix.getInfo())\n",
        "\n",
        "# Get confusion matrix data as a list of lists\n",
        "confusion_matrix_data = errorMatrix.array().getInfo()\n",
        "\n",
        "# Convert the list to a NumPy array\n",
        "matrix_values = np.array(confusion_matrix_data)  # Convert to NumPy array\n",
        "\n",
        "# Define class labels\n",
        "class_names = ['seagrass', 'nonSeagrass']  # Adjust if your class names are different\n",
        "\n",
        "# Create ConfusionMatrixDisplay object\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=matrix_values, display_labels=class_names)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel(\"EO prediction\", fontsize = 14)  # Change to your desired text\n",
        "plt.ylabel(\"In situ data\", fontsize = 14)\n",
        "disp.ax_.tick_params(axis='both', which='major', labelsize=18)  # Increase axis tick label size  # Change to your desired text\n",
        "plt.show()\n",
        "\n",
        "# Print accuracy metrics\n",
        "overall_accuracy = errorMatrix.accuracy().getInfo()\n",
        "print('Overall Accuracy:', overall_accuracy)\n",
        "producers_accuracy = ee.Array(errorMatrix.producersAccuracy()).reshape([-1]).getInfo()\n",
        "print('PA:', producers_accuracy)\n",
        "users_accuracy = ee.Array(errorMatrix.consumersAccuracy()).reshape([-1]).getInfo()\n",
        "print('UA:', users_accuracy)\n",
        "\n",
        "# Calcuate F1-score\n",
        "# Extract the components from the confusion matrix\n",
        "truePositives = errorMatrix.array().get([0, 0])\n",
        "falsePositives = errorMatrix.array().get([1, 0])\n",
        "falseNegatives = errorMatrix.array().get([0, 1])\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision = truePositives.divide(truePositives.add(falsePositives))\n",
        "recall = truePositives.divide(truePositives.add(falseNegatives))\n",
        "f1_score = ee.Number(2).multiply(precision.multiply(recall)).divide(precision.add(recall))\n",
        "\n",
        "print('F1-score:', f1_score.getInfo())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_3wcVxg8x4N"
      },
      "outputs": [],
      "source": [
        "## Calculate hectares\n",
        "seagrass_post = classification_images_post.select('classification').eq(0)\n",
        "\n",
        "# Step 3: Count number of seagrass pixels\n",
        "pixel_stats = seagrass_post.reduceRegion(\n",
        "    reducer=ee.Reducer.sum(),\n",
        "    geometry=OSW,\n",
        "    scale=3,\n",
        "    maxPixels=1e13\n",
        ")\n",
        "\n",
        "# Step 4: Convert to hectares (each 3x3m pixel = 9 mÂ² = 0.0009 ha)\n",
        "seagrass_pixel_count = ee.Number(pixel_stats.get('classification'))\n",
        "hectares = seagrass_pixel_count.multiply(0.0009)\n",
        "\n",
        "# Print the result\n",
        "print('Seagrass area (hectares):', hectares.getInfo())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paRpKGz5-gLy"
      },
      "outputs": [],
      "source": [
        "# ## Calculate hectares\n",
        "# seagrass_pre = classification_images_pre.select('classification').eq(0)\n",
        "\n",
        "# # Count number of seagrass pixels\n",
        "# pixel_stats = seagrass_pre.reduceRegion(\n",
        "#     reducer=ee.Reducer.sum(),\n",
        "#     geometry=OSW,\n",
        "#     scale=3,\n",
        "#     maxPixels=1e13\n",
        "# )\n",
        "\n",
        "# # Step 4: Convert to hectares (each 3x3m pixel = 9 mÂ² = 0.0009 ha)\n",
        "# seagrass_pixel_count = ee.Number(pixel_stats.get('classification'))\n",
        "# hectares = seagrass_pixel_count.multiply(0.0009)\n",
        "\n",
        "# # Print the result\n",
        "# print('Seagrass area (hectares):', hectares.getInfo())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "077N-2qzOijY"
      },
      "source": [
        "### Area quantification and +-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Np-xAezOjdD"
      },
      "outputs": [],
      "source": [
        "# Mask seagrass pixels\n",
        "seagrass_post = classification_images_post.eq(0)\n",
        "\n",
        "# create a binary mask: 1 = seagrass, 0 = not\n",
        "seagrass_mask = seagrass_post.rename('seagrass')  # change eq(0) if your seagrass label differs\n",
        "\n",
        "# count seagrass pixels (sum of 1s)\n",
        "pixel_count = seagrass_mask.reduceRegion(\n",
        "    reducer=ee.Reducer.sum(),\n",
        "    geometry=OSW.geometry(),\n",
        "    scale=3, # 3 m pixels\n",
        "    maxPixels=1e13\n",
        ").get('seagrass').getInfo()\n",
        "\n",
        "# convert to hectares: each pixel = 9 m2 -> 9/10000 = 0.0009 ha\n",
        "area_ha_post = pixel_count * 9.0 / 10000.0\n",
        "\n",
        "print(f\"Seagrass pixels: {pixel_count}, area: {area_ha_post} ha\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsdnmbLJO0vw"
      },
      "outputs": [],
      "source": [
        "# Scale probabilities from 0-100 to 0-1\n",
        "probabilities_post = probabilities.divide(100).select('seagrass')\n",
        "\n",
        "# Get the mean probability of seagrass over the region of interest\n",
        "mean_sum_prob_seagrass_post = probabilities_post.reduceRegion(\n",
        "    reducer=ee.Reducer.mean(),\n",
        "    geometry=OSW.geometry(),\n",
        "    scale=3, # Use the same scale as the area calculation\n",
        "    maxPixels=1e13\n",
        ").get('seagrass') # Get the mean value for the 'seagrass' band\n",
        "\n",
        "overall_accuracy_post = ee.Number(overall_accuracy) # Use the overall_accuracy from the pre-event validation cell\n",
        "\n",
        "# Get the total seagrass area for the pre-event classification (assuming it's stored in area_ha variable from cell ZfHt_UQ49oKf)\n",
        "# If not, you might need to recalculate it here or fetch it from the appropriate variable.\n",
        "total_seagrass_area_post = ee.Number(area_ha_post)\n",
        "\n",
        "# Calculate uncertainty for the pre-event seagrass area using the provided formula:\n",
        "# uncertainty = area * Overall Accuracy * (3 - mean of the sum of the probabilities predicted as seagrass) / 3\n",
        "# Assuming '3' is the number of images used in the pre-event period (sentinel2_l1c_pre has 3 images)\n",
        "num_images_post = ee.Number(1) # Set the number of pre-event images to 1 as an Earth Engine Number\n",
        "\n",
        "uncertainty_post_seagrass_area = total_seagrass_area_post.multiply(overall_accuracy_post).multiply(num_images_post.subtract(mean_sum_prob_seagrass_post)).divide(num_images_post)\n",
        "\n",
        "print(f\"Uncertainty of pre-event seagrass area: {area_ha_post:.2f} +- {uncertainty_post_seagrass_area.getInfo():.2f} ha\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJK-_1H0D2RX"
      },
      "source": [
        "#### 6.2.8 - Uncertainty analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lFIGzvT8DOh"
      },
      "outputs": [],
      "source": [
        "# ## To run uncertainties in the first classification (pre-event, 2018)\n",
        "# ## t=(9*OA*(3-median probabilities))/3\n",
        "# # 9 = area of pixel in square meters (3x3)\n",
        "# # 3 = number of images\n",
        "\n",
        "# ## first scale probabilities to 0-1 values\n",
        "# def scale_to_unit(image):\n",
        "#     return image.divide(100).copyProperties(image, image.propertyNames())\n",
        "\n",
        "# # Apply the scaling function to the collection\n",
        "# probabilities_01 = probabilities.map(scale_to_unit)\n",
        "\n",
        "# median_probability = probabilities_01.select('seagrass').median().rename('seagrass_median_prob')\n",
        "# median_probability\n",
        "\n",
        "# # Select the band containing median probability\n",
        "# median_probability = median_probability.select('seagrass_median_prob')\n",
        "\n",
        "# # Apply the formula:\n",
        "# # uncertainty = (9 * overall_accuracy * (3 - median_probability)) / 3\n",
        "# three = ee.Number(3)\n",
        "# nine = ee.Number(9)\n",
        "# oa = ee.Number(overall_accuracy)\n",
        "\n",
        "# # Compute: (3 - median_prob)\n",
        "# diff = ee.Image.constant(1).subtract(median_probability)\n",
        "\n",
        "# # Continue: (9 * overall_accuracy * diff) / 3\n",
        "# # uncertainty = (diff.multiply(oa).multiply(nine)).divide(three)\n",
        "# uncertainty = diff.divide(oa)\n",
        "\n",
        "# # Add the uncertainty as a new band\n",
        "# uncertainty_post = image.addBands(uncertainty.rename('uncertainty'))\n",
        "\n",
        "# region = uncertainty_post.geometry()\n",
        "# # Calculate min and max of the uncertainty band\n",
        "# stats = uncertainty_post.select('uncertainty').reduceRegion(\n",
        "#     reducer=ee.Reducer.minMax(),\n",
        "#     geometry=region,\n",
        "#     scale=3,\n",
        "#     maxPixels=1e9\n",
        "# )\n",
        "\n",
        "# # Get the results\n",
        "# min_val = stats.get('uncertainty_min').getInfo()\n",
        "# max_val = stats.get('uncertainty_max').getInfo()\n",
        "\n",
        "# print('Uncertainty range:', min_val, 'to', max_val)\n",
        "\n",
        "\n",
        "# # ###########################\n",
        "\n",
        "# # Select the uncertainty band\n",
        "# uncertainty_post = uncertainty_post.select('uncertainty')\n",
        "\n",
        "# # Normalize to 0â1\n",
        "# normalized_uncertainty = uncertainty_post.subtract(min_val).divide(max_val - min_val)\n",
        "\n",
        "# # Add it back to the image\n",
        "# overlap_mask = combined_classification_post.mask().reduce(ee.Reducer.anyNonZero())\n",
        "# uncertainty_post_norm = image.addBands(normalized_uncertainty.rename('uncertainty_norm'))\n",
        "\n",
        "# region = uncertainty_pre_norm.geometry()\n",
        "# # Calculate min and max of the uncertainty band\n",
        "# stats2 = uncertainty_post_norm.select('uncertainty_norm').reduceRegion(\n",
        "#     reducer=ee.Reducer.minMax(),\n",
        "#     geometry=region,\n",
        "#     scale=3,\n",
        "#     maxPixels=1e9\n",
        "# )\n",
        "\n",
        "# # Get the results\n",
        "# min_val = stats2.get('uncertainty_norm_min').getInfo()\n",
        "# max_val = stats2.get('uncertainty_norm_max').getInfo()\n",
        "\n",
        "# print('Uncertainty range norm:', min_val, 'to', max_val)\n",
        "\n",
        "# # Visualize the mean uncertainty layer\n",
        "# # Define visualization parameters for the uncertainty band\n",
        "# # You may need to adjust the min/max values based on your data range\n",
        "# vis_params = {'bands': ['uncertainty_norm'], 'palette': ['#4d004b', '#4f004d', '#50014e', '#520150', '#540251', '#550253', '#570354', '#580356', '#5a0457', '#5c0459', '#5d055a', '#5f055c', '#61065d', '#62065f', '#640761', '#650762', '#670864', '#690865', '#6a0867', '#6c0968', '#6e096a', '#6f0a6b', '#710a6d', '#730b6e', '#740b70', '#760c71', '#770c73', '#790d75', '#7b0d76', '#7c0e78', '#7e0e79', '#800f7b', '#810f7c', '#81117d', '#81127e', '#82147f', '#821580', '#821781', '#821982', '#831a83', '#831c84', '#831d85', '#831f86', '#832088', '#842289', '#84248a', '#84258b', '#84278c', '#85288d', '#852a8e', '#852b8f', '#852d90', '#852f91', '#863092', '#863293', '#863394', '#863595', '#873696', '#873897', '#873a98', '#873b99', '#873d9a', '#883e9b', '#88409c', '#88419d', '#88439e', '#88449e', '#88459f', '#8947a0', '#8948a0', '#8949a1', '#894ba2', '#894ca2', '#894da3', '#894fa3', '#8950a4', '#8a51a5', '#8a52a5', '#8a54a6', '#8a55a7', '#8a56a7', '#8a58a8', '#8a59a8', '#8a5aa9', '#8b5caa', '#8b5daa', '#8b5eab', '#8b60ac', '#8b61ac', '#8b62ad', '#8b64ad', '#8b65ae', '#8c66af', '#8c68af', '#8c69b0', '#8c6ab1', '#8c6cb1', '#8c6db2', '#8c6eb3', '#8c70b3', '#8c71b4', '#8c72b5', '#8c74b5', '#8c75b6', '#8c76b7', '#8c78b7', '#8c79b8', '#8c7ab8', '#8c7cb9', '#8c7dba', '#8c7eba', '#8c80bb', '#8c81bc', '#8c82bc', '#8c84bd', '#8c85be', '#8c86be', '#8c88bf', '#8c89c0', '#8c8bc0', '#8c8cc1', '#8c8dc2', '#8c8fc2', '#8c90c3', '#8c91c4', '#8c93c4', '#8c94c5', '#8c95c6', '#8c97c6', '#8d98c7', '#8d99c8', '#8e9ac8', '#8f9bc9', '#8f9dc9', '#909eca', '#909fcb', '#91a0cb', '#91a1cc', '#92a3cd', '#92a4cd', '#93a5ce', '#94a6ce', '#94a7cf', '#95a8d0', '#95aad0', '#96abd1', '#96acd2', '#97add2', '#98aed3', '#98b0d3', '#99b1d4', '#99b2d5', '#9ab3d5', '#9ab4d6', '#9bb6d7', '#9cb7d7', '#9cb8d8', '#9db9d9', '#9dbad9', '#9ebcda', '#9fbcda', '#a0bddb', '#a1bedb', '#a2bfdb', '#a3bfdc', '#a4c0dc', '#a5c1dc', '#a6c2dd', '#a7c2dd', '#a8c3de', '#a9c4de', '#aac4de', '#abc5df', '#acc6df', '#adc7e0', '#aec7e0', '#afc8e0', '#b0c9e1', '#b1c9e1', '#b2cae1', '#b3cbe2', '#b4cce2', '#b5cce3', '#b6cde3', '#b7cee3', '#b9cee4', '#bacfe4', '#bbd0e4', '#bcd1e5', '#bdd1e5', '#bed2e6', '#bfd3e6', '#c0d4e6', '#c1d4e7', '#c2d5e7', '#c3d6e8', '#c4d7e8', '#c5d8e9', '#c6d8e9', '#c7d9e9', '#c8daea', '#c9dbea', '#cadbeb', '#cbdceb', '#ccddec', '#cddeec', '#cedfec', '#cfdfed', '#d0e0ed', '#d1e1ee', '#d2e2ee', '#d3e2ef', '#d4e3ef', '#d6e4f0', '#d7e5f0', '#d8e6f0', '#d9e6f1', '#dae7f1', '#dbe8f2', '#dce9f2', '#ddeaf3', '#deeaf3', '#dfebf4', '#e0ecf4', '#e1ecf4', '#e1edf5', '#e2edf5', '#e3eef5', '#e4eef5', '#e4eff6', '#e5eff6', '#e6f0f6', '#e6f0f7', '#e7f1f7', '#e8f1f7', '#e9f2f7', '#e9f2f8', '#eaf3f8', '#ebf3f8', '#ebf4f8', '#ecf4f9', '#edf5f9', '#eef5f9', '#eef6fa', '#eff6fa', '#f0f7fa', '#f1f7fa', '#f1f8fb', '#f2f8fb', '#f3f9fb', '#f3f9fc', '#f4fafc', '#f5fafc', '#f6fbfc', '#f6fbfd', '#f7fcfd'], 'min': 0, 'max': 1}\n",
        "# Map = geemap.Map()\n",
        "# Map.addLayer(uncertainty_post_norm.select('uncertainty_norm'), vis_params, \"Uncertainty Post-event\")\n",
        "# Map.centerObject(OSW, 13)\n",
        "# Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IG5EHY5orJCm"
      },
      "outputs": [],
      "source": [
        "# # Export the FeatureCollection to Google Drive\n",
        "# task = ee.batch.Export.image.toDrive(\n",
        "#     image=uncertainty_post_norm.toFloat(),\n",
        "#     description='uncertainty_post_norm',  # Description for the task\n",
        "#     folder='Colab_Notebooks/export',\n",
        "#     region = OSW.geometry(),\n",
        "#     scale=3,  # Adjust the scale as needed\n",
        "#     fileFormat='GeoTIFF'  # Choose your desired file format (CSV, GeoJSON, KML, SHP, TFRecord)\n",
        "# )\n",
        "\n",
        "# # Start the export task\n",
        "# task.start()\n",
        "\n",
        "# print('Export task started. You can monitor its progress in the \"Tasks\" tab.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfYX56gED7Zr"
      },
      "source": [
        "# 7 - Seagrass change detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7JRnYMwY66P"
      },
      "outputs": [],
      "source": [
        "seagrass_pre = final_classification_pre.updateMask(final_classification_pre.select('classification').eq(0))\n",
        "seagrass_post = final_classification_post.updateMask(final_classification_post.select('classification').eq(0))\n",
        "\n",
        "seagrass_pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GemJi8lncc3a"
      },
      "outputs": [],
      "source": [
        "# Change from 0 to 1 (e.g., newly appeared features)\n",
        "gain = final_classification_pre.eq(1).And(final_classification_post.eq(0))\n",
        "\n",
        "# Change from 1 to 0 (e.g., disappeared features)\n",
        "loss = final_classification_pre.eq(0).And(final_classification_post.eq(1))\n",
        "\n",
        "# Stable seagrass meadows\n",
        "stable = final_classification_pre.eq(0).And(final_classification_post.eq(0))\n",
        "\n",
        "# Combine the conditions into a single image using 'where'\n",
        "seagrass_change = ee.Image(0) \\\n",
        "    .where(loss, 1) \\\n",
        "    .where(stable, 2) \\\n",
        "    .where(gain, 3)\n",
        "\n",
        "seagrass_change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGjquotNdcqO"
      },
      "outputs": [],
      "source": [
        "# Display the combined classification\n",
        "seagrass_change = seagrass_change.updateMask(land_mask).clip(OSW).selfMask()\n",
        "Map.addLayer(seagrass_change, {'min': 1, 'max': 3, 'palette': ['df8556', '42762f', '67688f']}, 'Combined Classification')\n",
        "Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpJqhKM0_D6Q"
      },
      "outputs": [],
      "source": [
        "# Define the export task\n",
        "task = ee.batch.Export.image.toDrive(\n",
        "    image=seagrass_change,\n",
        "    description='seagrass_change',  # Description for the task\n",
        "    folder='Colab_Notebooks/export',  # Folder in Google Drive to save the image (change if needed)\n",
        "    fileNamePrefix='seagrass_change',  # Prefix for the file name\n",
        "    region=roi,  # Region of interest (assuming 'roi' is defined)\n",
        "    scale=3,  # Scale in meters (adjust if needed)\n",
        "    fileFormat='GeoTIFF',  # File format\n",
        "    maxPixels=1e13  # Maximum number of pixels allowed (adjust if needed)\n",
        ")\n",
        "\n",
        "# Start the export task\n",
        "task.start()\n",
        "print('Export task started. You can monitor its progress in the \"Tasks\" tab.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brTB871yT4bU"
      },
      "outputs": [],
      "source": [
        "# # Visualize desirable bands to check data\n",
        "# s2_b8a_pre = multi_sensor_pre.first().select('S2_chl_re_mishra')\n",
        "\n",
        "# # Define visualization parameters for S2_B8A\n",
        "# # Adjust min/max values based on your data range\n",
        "# s2_b8a_vis = {\n",
        "#     'min': 0,\n",
        "#     'max': 0.15,  # Example max value, adjust as needed\n",
        "#     'palette': 'viridis' # Or any other suitable palette\n",
        "# }\n",
        "\n",
        "# Map.addLayer(s2_b8a_pre, s2_b8a_vis, \"Sentinel-2 chla\")\n",
        "# Map\n",
        "\n",
        "Map.addLayer(seagrass_samples_18, {'color': 'darkgreen'}, 'in situ seagrass 2018')\n",
        "Map.addLayer(nonSeagrass_samples_18, {'color': 'orange'}, 'in situ nonSeagrass 2018')\n",
        "\n",
        "Map.addLayer(sampledValidation_pre, {'color': 'pink'}, 'sampledValidation_pre')\n",
        "\n",
        "Map.addLayer(seagrass_samples_24, {'color': 'lightgreen'}, 'in situ seagrass 2024')\n",
        "Map.addLayer(nonSeagrass_samples_24, {'color': 'yellow'}, 'in situ nonSeagrass 2024')\n",
        "Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOsVYeshruWN"
      },
      "outputs": [],
      "source": [
        "# Select bands\n",
        "pre = uncertainty_pre_norm.select('uncertainty_norm')\n",
        "post = uncertainty_post_norm.select('uncertainty_norm')\n",
        "\n",
        "# Root-sum-of-squares\n",
        "uncertainty_change = pre.pow(2).add(post.pow(2)).sqrt().rename('uncertainty_change')\n",
        "\n",
        "# Optionally normalize or add to a base image\n",
        "result = image.addBands(uncertainty_change)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlCZK5-qsiWu"
      },
      "outputs": [],
      "source": [
        "region = OSW.geometry()\n",
        "# Calculate min and max of the uncertainty band\n",
        "stats2 = uncertainty_change.select('uncertainty_change').reduceRegion(\n",
        "    reducer=ee.Reducer.minMax(),\n",
        "    geometry=region,\n",
        "    scale=3,\n",
        "    maxPixels=1e9\n",
        ")\n",
        "\n",
        "# Get the results\n",
        "min_val = stats2.get('uncertainty_change_min').getInfo()\n",
        "max_val = stats2.get('uncertainty_change_max').getInfo()\n",
        "\n",
        "print('Uncertainty range:', min_val, 'to', max_val)\n",
        "\n",
        "# Select the uncertainty band\n",
        "uncertainty_change = uncertainty_change.select('uncertainty_change')\n",
        "\n",
        "# Normalize to 0â1\n",
        "normalized_uncertainty = uncertainty_change.subtract(min_val).divide(max_val - min_val)\n",
        "\n",
        "# Add it back to the image\n",
        "overlap_mask = uncertainty_change.mask().reduce(ee.Reducer.anyNonZero())\n",
        "uncertainty_change_norm = image.addBands(normalized_uncertainty.rename('uncertainty_change_norm'))\n",
        "\n",
        "region = uncertainty_pre_norm.geometry()\n",
        "# Calculate min and max of the uncertainty band\n",
        "stats2 = uncertainty_post_norm.select('uncertainty_change_norm').reduceRegion(\n",
        "    reducer=ee.Reducer.minMax(),\n",
        "    geometry=region,\n",
        "    scale=3,\n",
        "    maxPixels=1e9\n",
        ")\n",
        "\n",
        "# Get the results\n",
        "min_val = stats2.get('uncertainty_change_norm_min').getInfo()\n",
        "max_val = stats2.get('uncertainty_change_norm_max').getInfo()\n",
        "\n",
        "print('Uncertainty range norm:', min_val, 'to', max_val)\n",
        "\n",
        "\n",
        "# Visualize the mean uncertainty layer\n",
        "# Define visualization parameters for the uncertainty band\n",
        "# You may need to adjust the min/max values based on your data range\n",
        "vis_params = {'bands': ['uncertainty_change_norm'], 'palette': ['#4d004b', '#4f004d', '#50014e', '#520150', '#540251', '#550253', '#570354', '#580356', '#5a0457', '#5c0459', '#5d055a', '#5f055c', '#61065d', '#62065f', '#640761', '#650762', '#670864', '#690865', '#6a0867', '#6c0968', '#6e096a', '#6f0a6b', '#710a6d', '#730b6e', '#740b70', '#760c71', '#770c73', '#790d75', '#7b0d76', '#7c0e78', '#7e0e79', '#800f7b', '#810f7c', '#81117d', '#81127e', '#82147f', '#821580', '#821781', '#821982', '#831a83', '#831c84', '#831d85', '#831f86', '#832088', '#842289', '#84248a', '#84258b', '#84278c', '#85288d', '#852a8e', '#852b8f', '#852d90', '#852f91', '#863092', '#863293', '#863394', '#863595', '#873696', '#873897', '#873a98', '#873b99', '#873d9a', '#883e9b', '#88409c', '#88419d', '#88439e', '#88449e', '#88459f', '#8947a0', '#8948a0', '#8949a1', '#894ba2', '#894ca2', '#894da3', '#894fa3', '#8950a4', '#8a51a5', '#8a52a5', '#8a54a6', '#8a55a7', '#8a56a7', '#8a58a8', '#8a59a8', '#8a5aa9', '#8b5caa', '#8b5daa', '#8b5eab', '#8b60ac', '#8b61ac', '#8b62ad', '#8b64ad', '#8b65ae', '#8c66af', '#8c68af', '#8c69b0', '#8c6ab1', '#8c6cb1', '#8c6db2', '#8c6eb3', '#8c70b3', '#8c71b4', '#8c72b5', '#8c74b5', '#8c75b6', '#8c76b7', '#8c78b7', '#8c79b8', '#8c7ab8', '#8c7cb9', '#8c7dba', '#8c7eba', '#8c80bb', '#8c81bc', '#8c82bc', '#8c84bd', '#8c85be', '#8c86be', '#8c88bf', '#8c89c0', '#8c8bc0', '#8c8cc1', '#8c8dc2', '#8c8fc2', '#8c90c3', '#8c91c4', '#8c93c4', '#8c94c5', '#8c95c6', '#8c97c6', '#8d98c7', '#8d99c8', '#8e9ac8', '#8f9bc9', '#8f9dc9', '#909eca', '#909fcb', '#91a0cb', '#91a1cc', '#92a3cd', '#92a4cd', '#93a5ce', '#94a6ce', '#94a7cf', '#95a8d0', '#95aad0', '#96abd1', '#96acd2', '#97add2', '#98aed3', '#98b0d3', '#99b1d4', '#99b2d5', '#9ab3d5', '#9ab4d6', '#9bb6d7', '#9cb7d7', '#9cb8d8', '#9db9d9', '#9dbad9', '#9ebcda', '#9fbcda', '#a0bddb', '#a1bedb', '#a2bfdb', '#a3bfdc', '#a4c0dc', '#a5c1dc', '#a6c2dd', '#a7c2dd', '#a8c3de', '#a9c4de', '#aac4de', '#abc5df', '#acc6df', '#adc7e0', '#aec7e0', '#afc8e0', '#b0c9e1', '#b1c9e1', '#b2cae1', '#b3cbe2', '#b4cce2', '#b5cce3', '#b6cde3', '#b7cee3', '#b9cee4', '#bacfe4', '#bbd0e4', '#bcd1e5', '#bdd1e5', '#bed2e6', '#bfd3e6', '#c0d4e6', '#c1d4e7', '#c2d5e7', '#c3d6e8', '#c4d7e8', '#c5d8e9', '#c6d8e9', '#c7d9e9', '#c8daea', '#c9dbea', '#cadbeb', '#cbdceb', '#ccddec', '#cddeec', '#cedfec', '#cfdfed', '#d0e0ed', '#d1e1ee', '#d2e2ee', '#d3e2ef', '#d4e3ef', '#d6e4f0', '#d7e5f0', '#d8e6f0', '#d9e6f1', '#dae7f1', '#dbe8f2', '#dce9f2', '#ddeaf3', '#deeaf3', '#dfebf4', '#e0ecf4', '#e1ecf4', '#e1edf5', '#e2edf5', '#e3eef5', '#e4eef5', '#e4eff6', '#e5eff6', '#e6f0f6', '#e6f0f7', '#e7f1f7', '#e8f1f7', '#e9f2f7', '#e9f2f8', '#eaf3f8', '#ebf3f8', '#ebf4f8', '#ecf4f9', '#edf5f9', '#eef5f9', '#eef6fa', '#eff6fa', '#f0f7fa', '#f1f7fa', '#f1f8fb', '#f2f8fb', '#f3f9fb', '#f3f9fc', '#f4fafc', '#f5fafc', '#f6fbfc', '#f6fbfd', '#f7fcfd'], 'min': 0, 'max': 1}\n",
        "Map = geemap.Map()\n",
        "Map.addLayer(uncertainty_change_norm.select('uncertainty_change_norm'), vis_params, \"Uncertainty change\")\n",
        "Map.centerObject(OSW, 13)\n",
        "Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89307b20"
      },
      "outputs": [],
      "source": [
        "# # Define the export task\n",
        "# task = ee.batch.Export.image.toDrive(\n",
        "#     image=uncertainty_change_norm.toFloat(),\n",
        "#     description='uncertainty_change_norm',  # Description for the task\n",
        "#     folder='Colab_Notebooks/export',  # Folder in Google Drive to save the image (change if needed)\n",
        "#     fileNamePrefix='uncertainty_change_norm',  # Prefix for the file name\n",
        "#     region=roi,  # Region of interest (assuming 'roi' is defined)\n",
        "#     scale=3,  # Scale in meters (adjust if needed)\n",
        "#     fileFormat='GeoTIFF',  # File format\n",
        "#     maxPixels=1e13  # Maximum number of pixels allowed (adjust if needed)\n",
        "# )\n",
        "\n",
        "# # Start the export task\n",
        "# task.start()\n",
        "# print('Export task started. You can monitor its progress in the \"Tasks\" tab.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a880d81c"
      },
      "outputs": [],
      "source": [
        "## To extract feature importance and evaluate for PlanetScope 2018\n",
        "def soft_prob_subfn_ps18(image, num):\n",
        "       training = sampledData.map(lambda ft: ft.set(\n",
        "        'prob',\n",
        "        ee.Algorithms.If(ft.getNumber('habitat').eq(num), 1, 0)\n",
        "        ))\n",
        "\n",
        "       trained = ee.Classifier.smileRandomForest(numberOfTrees=trees) \\\n",
        "           .train(training, 'prob', image.bandNames()) \\\n",
        "           .setOutputMode('PROBABILITY')\n",
        "\n",
        "       dict_classifier = trained.explain()\n",
        "\n",
        "       # Create a Feature with the dictionary as a property\n",
        "       feature = ee.Feature(None, {'classifier_explanation': dict_classifier})\n",
        "\n",
        "       # Classify and convert to percentage scale\n",
        "       classified = image.classify(trained).multiply(100).toInt8()\n",
        "\n",
        "       # Return both the classified image and the Feature with explanation\n",
        "       return ee.Image(classified).set('classifier_explanation', feature)\n",
        "\n",
        "# Apply the function to the single PlanetScope 2018 image\n",
        "seagrass_prob_image_ps18 = soft_prob_subfn_ps18(classificationComp_pre, seagrass_class)\n",
        "\n",
        "### FEATURE IMPORTANCE FOR PLANETSCOPE 2018\n",
        "# Get the classifier explanation from the single image\n",
        "classifier_explanation_ps18 = seagrass_prob_image_ps18.get('classifier_explanation').getInfo()['properties']['classifier_explanation']\n",
        "importance_dict_ps18 = classifier_explanation_ps18.get('importance')\n",
        "\n",
        "# Sort features by importance in descending order\n",
        "sorted_importance_ps18 = dict(sorted(importance_dict_ps18.items(), key=lambda item: item[1], reverse=False))\n",
        "\n",
        "# Extract feature names and importance values\n",
        "feature_names_ps18 = list(sorted_importance_ps18.keys())\n",
        "importance_values_ps18 = list(sorted_importance_ps18.values())\n",
        "\n",
        "# Create a list of colors based on feature name prefix\n",
        "colors_ps18 = ['#005b96' if name.startswith('PS_') else '#6497b1' for name in feature_names_ps18]\n",
        "\n",
        "# Create the horizontal bar graph (switched axes)\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n",
        "plt.barh(feature_names_ps18, importance_values_ps18, color=colors_ps18) # Changed to barh for horizontal bars\n",
        "plt.ylabel(\"Features\") # Switched x and y labels\n",
        "plt.xlabel(\"Importance\") # Switched x and y labels\n",
        "plt.title(\"Feature Importance (2018)\")\n",
        "plt.show()  # Display the plot\n",
        "plt.tight_layout()\n",
        "\n",
        "selected_bands_ps18 = [band for band, importance in importance_dict_ps18.items() if importance >= 0]\n",
        "\n",
        "print(\"Selected bands (2018):\", selected_bands_ps18)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZYnUwfkbglaD",
        "tHJSLzJ2unAe",
        "lUAmKPh3qa_r",
        "uzS6h86aF0yr",
        "ilbT_ecVWRGi",
        "upgqHAHL0EZy",
        "lkUkRoVY6Nae",
        "KfYX56gED7Zr"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}